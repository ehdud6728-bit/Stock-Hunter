# ------------------------------------------------------------------
# ğŸ’ [Ultimate Masterpiece] ì „ì²œí›„ AI ì „ëµ ì‚¬ë ¹ë¶€ (Ver 36.0 í†µí•©íŒ)
# ------------------------------------------------------------------
import FinanceDataReader as fdr
import os, re, time, pytz
from pykrx import stock
import pandas as pd
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
import warnings
import requests
from bs4 import BeautifulSoup

# ğŸ‘‡ êµ¬ê¸€ ì‹œíŠ¸ ë§¤ë‹ˆì € ì—°ê²° (íŒŒì¼ëª… í™•ì¸ í•„ìˆ˜)
try:
    from google_sheet_managerEx import update_commander_dashboard
except ImportError:
    def update_commander_dashboard(*args, **kwargs): print("âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ëª¨ë“ˆ ì—°ê²° ì‹¤íŒ¨")

warnings.filterwarnings('ignore')

# =================================================
# âš™ï¸ [1. ì„¤ì • ë° ê¸€ë¡œë²Œ ë³€ìˆ˜]
# =================================================
SCAN_DAYS = 30     # ìµœê·¼ 30ì¼ ë‚´ íƒ€ì  ì „ìˆ˜ ì¡°ì‚¬
TOP_N = 250        # ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª© ìˆ˜ (í•„ìš”ì‹œ 2500ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥)
KST = pytz.timezone('Asia/Seoul')
NOW = datetime.now(KST)
TODAY_STR = NOW.strftime('%Y-%m-%d')
START_DATE = (datetime.now() - timedelta(days=600)).strftime('%Y-%m-%d')
END_DATE_STR = datetime.now().strftime('%Y%m%d')

print(f"ğŸ“¡ [Ver 36.0] ì‚¬ë ¹ë¶€ ë¬´ê²°ì„± í†µí•© ê°€ë™... ğŸ’ë‹¤ì´ì•„ëª¬ë“œ & ğŸ“Šë³µí•©í†µê³„ ì—”ì§„ íƒ‘ì¬")


# ---------------------------------------------------------
# ğŸŒ [ë§¤í¬ë¡œ ì—”ì§„] ê¸€ë¡œë²Œ ì§€ìˆ˜ ë° ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘
# ---------------------------------------------------------
def get_safe_macro(symbol, name):
    try:
        df = fdr.DataReader(symbol, start=(datetime.now() - timedelta(days=15)).strftime('%Y-%m-%d'))
        curr, prev = df.iloc[-1]['Close'], df.iloc[-2]['Close']
        ma5 = df['Close'].tail(5).mean()
        chg = ((curr - prev) / prev) * 100
        status = "â˜€ï¸ë§‘ìŒ" if curr > ma5 else "ğŸŒªï¸í­í’ìš°"
        if "VIX" in name: status = "â˜€ï¸ì•ˆì •" if curr < ma5 else "ğŸŒªï¸ìœ„í—˜"
        return {"val": curr, "chg": chg, "status": status, "text": f"{name}: {curr:,.2f}({chg:+.2f}%) {status}"}
    except: return {"status": "â˜ï¸ë¶ˆëª…", "text": f"{name}: ì—°ê²°ì‹¤íŒ¨"}

def get_index_investor_data(market_name):
    try:
        df = stock.get_market_net_purchases_of_equities(END_DATE_STR, END_DATE_STR, market_name)
        if df.empty:
            prev_day = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
            df = stock.get_market_net_purchases_of_equities(prev_day, prev_day, market_name)
        total = df.sum()
        return f"ê°œì¸ {total['ê°œì¸']:+,.0f} | ì™¸ì¸ {total['ì™¸êµ­ì¸']:+,.0f} | ê¸°ê´€ {total['ê¸°ê´€í•©ê³„']:+,.0f}"
    except: return "ë°ì´í„° ìˆ˜ì‹  ì¤‘..."

def prepare_historical_weather():
    """ì—­ì‚¬ì  ê¸°ìƒë„ë¥¼ ì‘ì„±í•˜ì—¬ analyze_finalì— ë³´ê¸‰í•©ë‹ˆë‹¤."""
    start_point = (datetime.now() - timedelta(days=600)).strftime('%Y-%m-%d')
    ndx = fdr.DataReader('^IXIC', start=start_point)[['Close']]
    sp5 = fdr.DataReader('^GSPC', start=start_point)[['Close']]
    ndx['ixic_ma5'] = ndx['Close'].rolling(5).mean()
    sp5['sp500_ma5'] = sp5['Close'].rolling(5).mean()
    weather_df = pd.concat([
        ndx.rename(columns={'Close': 'ixic_close'}),
        sp5.rename(columns={'Close': 'sp500_close'})
    ], axis=1).fillna(method='ffill')
    return weather_df
# ---------------------------------------------------------
# ğŸ“Š [ì „ìˆ  í†µê³„] ë³µí•© ì „ìˆ  í†µê³„ ì—”ì§„
# ---------------------------------------------------------
def calculate_strategy_stats(all_hits):
    past_hits = [h for h in all_hits if h['ë³´ìœ ì¼'] > 0]
    if not past_hits: return pd.DataFrame()
    stats = {}
    for h in past_hits:
        raw_tags = h['êµ¬ë¶„'].split()
        if not raw_tags: continue
        combos = [h['êµ¬ë¶„']]
        if len(raw_tags) > 1:
            raw_tags.sort()
            combos.append(" + ".join(raw_tags)) 
        for strategy in set(combos):
            if strategy not in stats: 
                stats[strategy] = {'total': 0, 'hits': 0, 'yields': []}
            stats[strategy]['total'] += 1
            if h['ìµœê³ _raw'] >= 3.5: stats[strategy]['hits'] += 1
            stats[strategy]['yields'].append(h['ìµœê³ _raw'])

    report_data = []
    for strategy, data in stats.items():
        avg_yield = sum(data['yields']) / data['total']
        hit_rate = (data['hits'] / data['total']) * 100
        report_data.append({'ì „ëµëª…': strategy, 'í¬ì°©ê±´ìˆ˜': data['total'], 'íƒ€ìœ¨(ìŠ¹ë¥ )': round(hit_rate, 1), 'í‰ê· ìµœê³ ìˆ˜ìµ': round(avg_yield, 1)})
    return pd.DataFrame(report_data).sort_values(by=['í‰ê· ìµœê³ ìˆ˜ìµ', 'íƒ€ìœ¨(ìŠ¹ë¥ )'], ascending=False)

# ---------------------------------------------------------
# ğŸ“ˆ [ë°ì´í„°] ë§ˆìŠ¤í„° ì§€í‘œ ì—”ì§„ (Ver 36.0 ì¼ëª©ê· í˜•í‘œ í¬í•¨)
# ---------------------------------------------------------
def get_indicators(df):
    df = df.copy()
    count = len(df)
    # ë‹¨í…Œ ì¥ê¸°ì„  í¬í•¨ ì´í‰ì„ 
    for n in [5, 20, 40, 60, 112, 224]:
        df[f'MA{n}'] = df['Close'].rolling(window=min(count, n)).mean()
        df[f'VMA{n}'] = df['Volume'].rolling(window=min(count, n)).mean()
    
    # 20/40ì¼ BB Width (ì´ì¤‘ ì‘ì¶•)
    std20 = df['Close'].rolling(20).std()
    df['BB_Upper'] = df['MA20'] + (std20 * 2)
    df['BB20_Width'] = (std20 * 4) / df['MA20'] * 100
    std40 = df['Close'].rolling(40).std()
    df['BB40_Upper'] = df['MA40'] + (std40 * 2)
    df['BB40_Width'] = (std40 * 4) / df['MA40'] * 100
    
    # ì¼ëª©ê· í˜•í‘œ (ì˜ì„± íƒì§€)
    df['Tenkan_sen'] = (df['High'].rolling(9).max() + df['Low'].rolling(9).min()) / 2
    df['Kijun_sen'] = (df['High'].rolling(26).max() + df['Low'].rolling(26).min()) / 2
    df['Span_A'] = ((df['Tenkan_sen'] + df['Kijun_sen']) / 2).shift(26)
    df['Span_B'] = ((df['High'].rolling(52).max() + df['Low'].rolling(52).min()) / 2).shift(26)
    df['Cloud_Top'] = df[['Span_A', 'Span_B']].max(axis=1)

    # ìŠ¤í† ìºìŠ¤í‹± / ADX / MACD / OBV
    l_min, h_max = df['Low'].rolling(12).min(), df['High'].rolling(12).max()
    df['Sto_K'] = ((df['Close'] - l_min) / (h_max - l_min)) * 100
    df['Sto_D'] = df['Sto_K'].rolling(5).mean()
    df['Sto_SD'] = df['Sto_D'].rolling(5).mean()
    
    high, low, close = df['High'], df['Low'], df['Close']
    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)
    df['ADX'] = ((abs((high-high.shift(1)).clip(lower=0).rolling(14).sum() - (low.shift(1)-low).clip(lower=0).rolling(14).sum()) / 
                ((high-high.shift(1)).clip(lower=0).rolling(14).sum() + (low.shift(1)-low).clip(lower=0).rolling(14).sum())) * 100).rolling(14).mean()
    df['MACD_Hist'] = (df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()) - (df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()).ewm(span=9).mean()
    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
    df['OBV_Slope'] = (df['OBV'] - df['OBV'].shift(5)) / df['OBV'].shift(5).abs() * 100
    df['Disparity'] = (df['Close'] / df['MA20']) * 100
    return df

# ---------------------------------------------------------
# ğŸ•µï¸â€â™‚ï¸ [ë¶„ì„] ì •ë°€ ë¶„ì„ ì—”ì§„ (Ver 36.0 ë‹¤ì´ì•„ëª¬ë“œ í†µí•©)
# ---------------------------------------------------------
# ---------------------------------------------------------
# ğŸ•µï¸â€â™‚ï¸ [ë¶„ì„] ì •ë°€ ë¶„ì„ ì—”ì§„ (Ver 36.5: í­ë°œì§ì „ í•„í„° í†µí•©)
# ---------------------------------------------------------
def analyze_final(ticker, name, historical_indices):
    try:
        df = fdr.DataReader(ticker, start=START_DATE)
        if len(df) < 100: return []
        df = get_indicators(df)
        df = df.join(historical_indices, how='left').fillna(method='ffill')
        
        # ìµœì‹  ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘ (ìƒëµ ë°©ì§€)
        url = f"https://finance.naver.com/item/frgn.naver?code={ticker}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=5)
        res.encoding = 'euc-kr'
        supply_df = pd.read_html(res.text)[2].dropna()
        f_qty = int(str(supply_df.iloc[0]['ì™¸êµ­ì¸']).replace('.0','').replace(',',''))
        i_qty = int(str(supply_df.iloc[0]['ê¸°ê´€']).replace('.0','').replace(',',''))
        twin_b = (f_qty > 0 and i_qty > 0)
        whale_score = int(((f_qty + i_qty) * df.iloc[-1]['Close']) / 100000000)

        recent_df = df.tail(SCAN_DAYS)
        hits = []

        for curr_idx, row in recent_df.iterrows():
            raw_idx = df.index.get_loc(curr_idx)
            if raw_idx < 100: continue
            prev = df.iloc[raw_idx-1]
            
            # 1. ê¼¬ë¦¬% ì •ë°€ ê³„ì‚°
            high_p, low_p, close_p, open_p = row['High'], row['Low'], row['Close'], row['Open']
            body_max = max(open_p, close_p)
            t_pct = int((high_p - body_max) / (high_p - low_p) * 100) if high_p != low_p else 0

            # 2. í•µì‹¬ ì „ìˆ  ì‹ í˜¸ íŒì •
            is_cloud_brk = prev['Close'] <= prev['Cloud_Top'] and close_p > row['Cloud_Top']
            is_kijun_sup = close_p > row['Kijun_sen'] and prev['Close'] <= prev['Kijun_sen']
            is_diamond = is_cloud_brk and is_kijun_sup
            
            is_super_squeeze = row['BB20_Width'] < 10 and row['BB40_Width'] < 15
            is_yeok_mae = close_p > row['MA112'] and prev['Close'] <= row['MA112']
            is_vol_power = row['Volume'] > row['VMA20'] * 2.5 # ê±°ë˜ëŸ‰ 250% í­ë°œ

            # 3. ì ìˆ˜ ì‚°ì¶œ ë° íƒœê·¸ ë¶€ì—¬
            s_score = 100
            tags = []
            
            if is_diamond:
                s_score += 150
                tags.append("ğŸ’ë‹¤ì´ì•„ëª¬ë“œ")
                # ğŸ’¡ [ì‹ ê·œ] í­ë°œì§ì „ í•„í„°: ë‹¤ì´ì•„ëª¬ë“œì¸ë° ê¼¬ë¦¬ê°€ 10% ë¯¸ë§Œì¼ ë•Œ
                if t_pct < 10:
                    s_score += 50
                    tags.append("ğŸ”¥í­ë°œì§ì „")
            
            elif is_cloud_brk:
                s_score += 40; tags.append("â˜ï¸êµ¬ë¦„ëŒíŒŒ")

            if is_yeok_mae: s_score += 40; tags.append("ğŸ†ì—­ë§¤ê³µíŒŒ")
            if is_super_squeeze: s_score += 40; tags.append("ğŸ”‹ì´ˆê°•ë ¥ì‘ì¶•")
            if is_vol_power: s_score += 30; tags.append("âš¡ê±°ë˜í­ë°œ")
            
            # ê¼¬ë¦¬ ê°ì  ë¡œì§ (ë‹¤ì´ì•„ëª¬ë“œê°€ ì•„ë‹ ë•Œ ë” ì—„ê²©í•˜ê²Œ ì ìš©)
            if t_pct > 40:
                s_score -= 25
                tags.append("âš ï¸ìœ—ê¼¬ë¦¬")
            if row['BB40_Width'] < 15: tags.append("ë°´ë“œ(40)")

            # ê¸°ìƒë„ ë° ê³¼ì—´(ì´ê²©ë„) ê°ì 
            storm_count = sum([1 for m in ['ixic', 'sp500'] if row[f'{m}_close'] <= row[f'{m}_ma5']])
            s_score -= (storm_count * 20)
            s_score -= max(0, int((row['Disparity']-108)*5)) 
            
            if not tags: continue

            # 4. ìˆ˜ìµë¥  ê²€ì¦ ë°ì´í„° ìƒì„±
            h_df = df.iloc[raw_idx+1:]
            max_r = ((h_df['High'].max()-close_p)/close_p)*100 if not h_df.empty else 0
            curr_r = ((h_df['Close'].iloc[-1]-close_p)/close_p)*100 if not h_df.empty else 0

            hits.append({
                'ë‚ ì§œ': curr_idx.strftime('%Y-%m-%d'),
                'ê¸°ìƒ': "â˜€ï¸" * (2-storm_count) + "ğŸŒªï¸" * storm_count,
                'ì•ˆì „': int(max(0, s_score + whale_score)),
                'ì¢…ëª©': name,
                'í˜„ì¬ê°€': int(close_p),
                'ê¼¬ë¦¬%': t_pct,
                'ì´ê²©': int(row['Disparity']),
                'ğŸ”ºìµœê³ ': f"{max_r:+.1f}%",
                'í˜„ì¬': f"{curr_r:+.1f}%",
                'í˜„ì¬_raw': curr_r, 'ìµœê³ _raw': max_r,
                'êµ¬ë¶„': " ".join(tags),
                'ë³´ìœ ì¼': len(h_df)
            })
        return hits
    except: return [] #=================================================
# ğŸš€ [ì‹¤í–‰] ë©”ì¸ ì»¨íŠ¸ë¡¤ëŸ¬
# #=================================================
if __name__ == "__main__":
    print(f"ğŸ“¡ [Ver 36.5] {TODAY_STR} ì „ìˆ  ì‚¬ë ¹ë¶€ í†µí•© ê°€ë™...")

    # 1. ë§¤í¬ë¡œ ë°ì´í„° ìˆ˜ì§‘ (get_safe_macroê°€ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨)
    m_ndx = get_safe_macro('^IXIC', 'ë‚˜ìŠ¤ë‹¥')
    m_sp5 = get_safe_macro('^GSPC', 'S&P500')
    m_vix = get_safe_macro('^VIX', 'VIXê³µí¬')
    m_fx  = get_safe_macro('USD/KRW', 'ë‹¬ëŸ¬í™˜ìœ¨')
    
    # KOSPI ìˆ˜ê¸‰ ë°ì´í„°
    kospi_supply = get_index_investor_data('KOSPI')
    macro_status = {'nasdaq': m_ndx, 'sp500': m_sp5, 'vix': m_vix, 'fx': m_fx, 'kospi': kospi_supply}

    print("\n" + "ğŸŒ " * 5 + "[ ê¸€ë¡œë²Œ ì‚¬ë ¹ë¶€ í†µí•© ê´€ì œ ì„¼í„° ]" + " ğŸŒ" * 5)
    print(f"ğŸ‡ºğŸ‡¸ {m_ndx['text']} | {m_sp5['text']} | âš ï¸ {m_vix['text']}")
    print(f"ğŸ’µ {m_fx['text']} | ğŸ‡°ğŸ‡· KOSPI ìˆ˜ê¸‰: {kospi_supply}")
    print("=" * 115)

    # 2. ì „ ì¢…ëª© ë¦¬ìŠ¤íŒ… ë° ê¸°ìƒë„ ì¤€ë¹„
    df_krx = fdr.StockListing('KRX')
    # ğŸ’¡ target_stocks ì •ì˜ (NameError ë°©ì§€)
    target_stocks = df_krx.sort_values(by='Amount', ascending=False).head(TOP_N)
    # ğŸ’¡ weather_data ì¤€ë¹„ (analyze_finalì— ì „ë‹¬ìš©)
    weather_data = prepare_historical_weather()
    
    # 3. ì „ìˆ  ìŠ¤ìº” (ë©€í‹°ìŠ¤ë ˆë”©)
    all_hits = []
    print(f"ğŸ” ì´ {len(target_stocks)}ê°œ ì¢…ëª© ğŸ’ë‹¤ì´ì•„ëª¬ë“œ ë ˆì´ë” ê°€ë™...")
    with ThreadPoolExecutor(max_workers=15) as executor:
        # lambda pì—ì„œ p[0]: Code, p[1]: Name, weather_data: ê¸°ìƒë„ ì „ë‹¬
        results = list(executor.map(
            lambda p: analyze_final(p[0], p[1], weather_data), 
            zip(target_stocks['Code'], target_stocks['Name'])
        ))
        for r in results:
            if r: all_hits.extend(r)

    if all_hits:
        df_total = pd.DataFrame(all_hits)
        # ğŸ’¡ ë³µí•© ì „ìˆ  í†µê³„ ì‚°ì¶œ
        stats_df = calculate_strategy_stats(all_hits)
        
        # 4. ê²°ê³¼ ë¶„ë¥˜ ë° ë¦¬í¬íŠ¸
        today = df_total[df_total['ë³´ìœ ì¼'] == 0].sort_values(by='ì•ˆì „', ascending=False)
        print("\n" + "ğŸ”¥ [ì˜¤ëŠ˜ì˜ ì´ˆì •ì˜ˆ ë‹¤ì´ì•„ëª¬ë“œ íƒ€ì ] " + "="*50)
        print(today[['ë‚ ì§œ', 'ì•ˆì „', 'ì¢…ëª©', 'ê¼¬ë¦¬%', 'êµ¬ë¶„']].head(20))

        # 5. êµ¬ê¸€ ì‹œíŠ¸ ì „ì†¡
        try:
            update_commander_dashboard(df_total, macro_status, "ì‚¬ë ¹ë¶€_í†µí•©_ìƒí™©íŒ", stats_df)
            print("\nâœ… êµ¬ê¸€ ì‹œíŠ¸ ë° ì „ìˆ  í†µê³„ ì—…ë°ì´íŠ¸ ì„±ê³µ!")
        except Exception as e:
            print(f"\nâŒ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")