# ------------------------------------------------------------------
# ğŸ’ [Ultimate Masterpiece] ì „ì²œí›„ AI ì „ëµ ì‚¬ë ¹ë¶€ (Ver 36.7 ì—‘ì…€ì €ì¥+ì¶”ì²œì‹œìŠ¤í…œ)
# ------------------------------------------------------------------
import FinanceDataReader as fdr
import os, re, time, pytz
from pykrx import stock
import pandas as pd
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
import warnings
import requests
from bs4 import BeautifulSoup
from DNA_Analyzer import analyze_dna_sequences, find_winning_pattern

# ğŸ‘‡ êµ¬ê¸€ ì‹œíŠ¸ ë§¤ë‹ˆì € ì—°ê²° (íŒŒì¼ëª… í™•ì¸ í•„ìˆ˜)
try:
    from google_sheet_managerEx import update_commander_dashboard
except ImportError:
    def update_commander_dashboard(*args, **kwargs): print("âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ëª¨ë“ˆ ì—°ê²° ì‹¤íŒ¨")

warnings.filterwarnings('ignore')

# =================================================
# âš™ï¸ [1. ì„¤ì • ë° ê¸€ë¡œë²Œ ë³€ìˆ˜]
# =================================================
SCAN_DAYS = 20     # ìµœê·¼ 30ì¼ ë‚´ íƒ€ì  ì „ìˆ˜ ì¡°ì‚¬
TOP_N = 2500        # ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª© ìˆ˜ (í•„ìš”ì‹œ 2500ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥)
KST = pytz.timezone('Asia/Seoul')
NOW = datetime.now(KST)
TODAY_STR = NOW.strftime('%Y-%m-%d')
START_DATE = (datetime.now() - timedelta(days=600)).strftime('%Y-%m-%d')
END_DATE_STR = datetime.now().strftime('%Y%m%d')

print(f"ğŸ“¡ [Ver 36.7 ì—‘ì…€ì €ì¥+ì¶”ì²œ] ì‚¬ë ¹ë¶€ ë¬´ê²°ì„± í†µí•© ê°€ë™... ğŸ’ë‹¤ì´ì•„ëª¬ë“œ & ğŸ“Šë³µí•©í†µê³„ ì—”ì§„ íƒ‘ì¬")


# ---------------------------------------------------------
# ğŸŒ [ë§¤í¬ë¡œ ì—”ì§„] ê¸€ë¡œë²Œ ì§€ìˆ˜ ë° ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘
# ---------------------------------------------------------
def get_safe_macro(symbol, name):
    try:
        df = fdr.DataReader(symbol, start=(datetime.now() - timedelta(days=15)).strftime('%Y-%m-%d'))
        curr, prev = df.iloc[-1]['Close'], df.iloc[-2]['Close']
        ma5 = df['Close'].tail(5).mean()
        chg = ((curr - prev) / prev) * 100
        status = "â˜€ï¸ë§‘ìŒ" if curr > ma5 else "ğŸŒªï¸í­í’ìš°"
        if "VIX" in name: status = "â˜€ï¸ì•ˆì •" if curr < ma5 else "ğŸŒªï¸ìœ„í—˜"
        return {"val": curr, "chg": chg, "status": status, "text": f"{name}: {curr:,.2f}({chg:+.2f}%) {status}"}
    except: return {"status": "â˜ï¸ë¶ˆëª…", "text": f"{name}: ì—°ê²°ì‹¤íŒ¨"}

def get_index_investor_data(market_name):
    try:
        df = stock.get_market_net_purchases_of_equities(END_DATE_STR, END_DATE_STR, market_name)
        if df.empty:
            prev_day = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
            df = stock.get_market_net_purchases_of_equities(prev_day, prev_day, market_name)
        total = df.sum()
        return f"ê°œì¸ {total['ê°œì¸']:+,.0f} | ì™¸ì¸ {total['ì™¸êµ­ì¸']:+,.0f} | ê¸°ê´€ {total['ê¸°ê´€í•©ê³„']:+,.0f}"
    except: return "ë°ì´í„° ìˆ˜ì‹  ì¤‘..."

def prepare_historical_weather():
    """ì—­ì‚¬ì  ê¸°ìƒë„ë¥¼ ì‘ì„±í•˜ì—¬ analyze_finalì— ë³´ê¸‰í•©ë‹ˆë‹¤."""
    start_point = (datetime.now() - timedelta(days=600)).strftime('%Y-%m-%d')
    ndx = fdr.DataReader('^IXIC', start=start_point)[['Close']]
    sp5 = fdr.DataReader('^GSPC', start=start_point)[['Close']]
    ndx['ixic_ma5'] = ndx['Close'].rolling(5).mean()
    sp5['sp500_ma5'] = sp5['Close'].rolling(5).mean()
    weather_df = pd.concat([
        ndx.rename(columns={'Close': 'ixic_close'}),
        sp5.rename(columns={'Close': 'sp500_close'})
    ], axis=1).fillna(method='ffill')
    return weather_df

# ---------------------------------------------------------
# ğŸ“Š [ì „ìˆ  í†µê³„] ë³µí•© ì „ìˆ  í†µê³„ ì—”ì§„ (ìƒìœ„ 5ê°œ ì¶”ì²œ)
# ---------------------------------------------------------
def calculate_strategy_stats(all_hits):
    past_hits = [h for h in all_hits if h['ë³´ìœ ì¼'] > 0]
    if not past_hits: return pd.DataFrame(), None
    
    stats = {}
    for h in past_hits:
        raw_tags = h['êµ¬ë¶„'].split()
        if not raw_tags: continue
        
        # ê°œë³„ íƒœê·¸ ë° ë³µí•© íƒœê·¸ ìƒì„±
        combos = []
        for tag in raw_tags:
            combos.append(tag)
        
        # 2ê°œ ì¡°í•©
        if len(raw_tags) >= 2:
            sorted_tags = sorted(raw_tags)
            for i in range(len(sorted_tags)):
                for j in range(i+1, len(sorted_tags)):
                    combos.append(f"{sorted_tags[i]} + {sorted_tags[j]}")
        
        # ì „ì²´ ì¡°í•©
        if len(raw_tags) > 1:
            combos.append(" + ".join(sorted(raw_tags)))
        
        for strategy in set(combos):
            if strategy not in stats: 
                stats[strategy] = {'total': 0, 'hits': 0, 'yields': [], 'min_yields': []}
            stats[strategy]['total'] += 1
            if h['ìµœê³ ìˆ˜ìµë¥ _raw'] >= 3.5: stats[strategy]['hits'] += 1
            stats[strategy]['yields'].append(h['ìµœê³ ìˆ˜ìµë¥ _raw'])
            stats[strategy]['min_yields'].append(h['ìµœì €ìˆ˜ìµë¥ _raw'])

    report_data = []
    for strategy, data in stats.items():
        avg_max_yield = sum(data['yields']) / data['total']
        avg_min_yield = sum(data['min_yields']) / data['total']
        hit_rate = (data['hits'] / data['total']) * 100
        
        # ê¸°ëŒ€ê°’ ê³„ì‚° (í™•ë¥  * ìˆ˜ìµë¥ )
        expected_value = (hit_rate / 100) * avg_max_yield
        
        report_data.append({
            'ì „ëµëª…': strategy, 
            'í¬ì°©ê±´ìˆ˜': data['total'], 
            'íƒ€ìœ¨(ìŠ¹ë¥ )': round(hit_rate, 1), 
            'í‰ê· ìµœê³ ìˆ˜ìµ': round(avg_max_yield, 1),
            'í‰ê· ìµœì €ìˆ˜ìµ': round(avg_min_yield, 1),
            'ê¸°ëŒ€ê°’': round(expected_value, 2)
        })
    
    df_stats = pd.DataFrame(report_data).sort_values(
        by=['ê¸°ëŒ€ê°’', 'í‰ê· ìµœê³ ìˆ˜ìµ', 'íƒ€ìœ¨(ìŠ¹ë¥ )'], 
        ascending=False
    )
    
    # ğŸ’¡ ìƒìœ„ 3~5ê°œ íŒ¨í„´ ì¶”ì²œ
    top_recommendations = []
    if len(df_stats) > 0:
        # ìµœì†Œ 5ê±´ ì´ìƒ ë°ì´í„° ìˆëŠ” íŒ¨í„´ ìš°ì„ 
        reliable_patterns = df_stats[df_stats['í¬ì°©ê±´ìˆ˜'] >= 5]
        
        if len(reliable_patterns) >= 3:
            # ì‹ ë¢°ë„ ë†’ì€ íŒ¨í„´ ì¤‘ ìƒìœ„ 5ê°œ
            top_5 = reliable_patterns.head(5)
            for idx, row in top_5.iterrows():
                top_recommendations.append({
                    'ìˆœìœ„': len(top_recommendations) + 1,
                    'íŒ¨í„´': row['ì „ëµëª…'],
                    'íƒ€ìœ¨': row['íƒ€ìœ¨(ìŠ¹ë¥ )'],
                    'í‰ê· ìˆ˜ìµ': row['í‰ê· ìµœê³ ìˆ˜ìµ'],
                    'ê¸°ëŒ€ê°’': row['ê¸°ëŒ€ê°’'],
                    'ê±´ìˆ˜': row['í¬ì°©ê±´ìˆ˜'],
                    'ì‹ ë¢°ë„': 'â­â­â­ ë†’ìŒ'
                })
        else:
            # ë°ì´í„° ë¶€ì¡±ì‹œ ì „ì²´ì—ì„œ ìƒìœ„ 5ê°œ
            top_5 = df_stats.head(5)
            for idx, row in top_5.iterrows():
                reliability = 'â­â­â­ ë†’ìŒ' if row['í¬ì°©ê±´ìˆ˜'] >= 5 else 'â­â­ ë³´í†µ' if row['í¬ì°©ê±´ìˆ˜'] >= 3 else 'â­ ì£¼ì˜'
                top_recommendations.append({
                    'ìˆœìœ„': len(top_recommendations) + 1,
                    'íŒ¨í„´': row['ì „ëµëª…'],
                    'íƒ€ìœ¨': row['íƒ€ìœ¨(ìŠ¹ë¥ )'],
                    'í‰ê· ìˆ˜ìµ': row['í‰ê· ìµœê³ ìˆ˜ìµ'],
                    'ê¸°ëŒ€ê°’': row['ê¸°ëŒ€ê°’'],
                    'ê±´ìˆ˜': row['í¬ì°©ê±´ìˆ˜'],
                    'ì‹ ë¢°ë„': reliability
                })
    
    return df_stats, top_recommendations

# ---------------------------------------------------------
# ğŸ“ˆ [ë°ì´í„°] ë§ˆìŠ¤í„° ì§€í‘œ ì—”ì§„ (Ver 36.7)
# ---------------------------------------------------------
def get_indicators(df):
    df = df.copy()
    count = len(df)
    
    # ë‹¨í…Œ ì¥ê¸°ì„  í¬í•¨ ì´í‰ì„ 
    for n in [5, 20, 40, 60, 112, 224]:
        df[f'MA{n}'] = df['Close'].rolling(window=min(count, n)).mean()
        df[f'VMA{n}'] = df['Volume'].rolling(window=min(count, n)).mean()
    
    # 20/40ì¼ BB Width (ì´ì¤‘ ì‘ì¶•)
    std20 = df['Close'].rolling(20).std()
    df['BB_Upper'] = df['MA20'] + (std20 * 2)
    df['BB20_Width'] = (std20 * 4) / df['MA20'] * 100
    std40 = df['Close'].rolling(40).std()
    df['BB40_Upper'] = df['MA40'] + (std40 * 2)
    df['BB40_Lower'] = df['MA40'] - (std40 * 2)
    df['BB40_Width'] = (std40 * 4) / df['MA40'] * 100
    
    # ì´í‰ì„  ìˆ˜ë ´ë„ ê³„ì‚°
    df['MA_Convergence'] = abs(df['MA20'] - df['MA60']) / df['MA60'] * 100
    
    # ì¼ëª©ê· í˜•í‘œ
    df['Tenkan_sen'] = (df['High'].rolling(9).max() + df['Low'].rolling(9).min()) / 2
    df['Kijun_sen'] = (df['High'].rolling(26).max() + df['Low'].rolling(26).min()) / 2
    df['Span_A'] = ((df['Tenkan_sen'] + df['Kijun_sen']) / 2).shift(26)
    df['Span_B'] = ((df['High'].rolling(52).max() + df['Low'].rolling(52).min()) / 2).shift(26)
    df['Cloud_Top'] = df[['Span_A', 'Span_B']].max(axis=1)

    # ìŠ¤í† ìºìŠ¤í‹±
    l_min, h_max = df['Low'].rolling(12).min(), df['High'].rolling(12).max()
    df['Sto_K'] = ((df['Close'] - l_min) / (h_max - l_min)) * 100
    df['Sto_D'] = df['Sto_K'].rolling(5).mean()
    df['Sto_SD'] = df['Sto_D'].rolling(5).mean()
    
    # ADX
    high, low, close = df['High'], df['Low'], df['Close']
    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)
    df['ADX'] = ((abs((high-high.shift(1)).clip(lower=0).rolling(14).sum() - (low.shift(1)-low).clip(lower=0).rolling(14).sum()) / 
                ((high-high.shift(1)).clip(lower=0).rolling(14).sum() + (low.shift(1)-low).clip(lower=0).rolling(14).sum())) * 100).rolling(14).mean()
    
    # MACD
    ema12 = df['Close'].ewm(span=12).mean()
    ema26 = df['Close'].ewm(span=26).mean()
    df['MACD'] = ema12 - ema26
    df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']
    
    # OBV
    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
    df['OBV_Slope'] = (df['OBV'] - df['OBV'].shift(5)) / df['OBV'].shift(5).abs() * 100
    
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    
    df['Disparity'] = (df['Close'] / df['MA20']) * 100
    df['Box_Range'] = df['High'].rolling(10).max() / df['Low'].rolling(10).min()
    
    return df

# ---------------------------------------------------------
# ğŸ•µï¸â€â™‚ï¸ [ë¶„ì„] ì •ë°€ ë¶„ì„ ì—”ì§„ (Ver 36.7 ìµœì €ìˆ˜ìµë¥  ì¶”ê°€)
# ---------------------------------------------------------
def analyze_final(ticker, name, historical_indices):
    try:
        df = fdr.DataReader(ticker, start=START_DATE)
        if len(df) < 100: return []
        df = get_indicators(df)
        df = df.join(historical_indices, how='left').fillna(method='ffill')
        
        # ğŸ’¡ ì˜¤ëŠ˜ì˜ í˜„ì¬ê°€ ì €ì¥ (ë‚˜ì¤‘ì— ì‚¬ìš©)
        today_price = df.iloc[-1]['Close']
        
        # ìµœì‹  ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘
        try:
            url = f"https://finance.naver.com/item/frgn.naver?code={ticker}"
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=5)
            res.encoding = 'euc-kr'
            supply_df = pd.read_html(res.text)[2].dropna()
            f_qty = int(str(supply_df.iloc[0]['ì™¸êµ­ì¸']).replace('.0','').replace(',',''))
            i_qty = int(str(supply_df.iloc[0]['ê¸°ê´€']).replace('.0','').replace(',',''))
            twin_b = (f_qty > 0 and i_qty > 0)
            whale_score = int(((f_qty + i_qty) * df.iloc[-1]['Close']) / 100000000)
        except:
            f_qty, i_qty, twin_b, whale_score = 0, 0, False, 0

        recent_df = df.tail(SCAN_DAYS)
        hits = []

        for curr_idx, row in recent_df.iterrows():
            raw_idx = df.index.get_loc(curr_idx)
            if raw_idx < 100: continue
            prev = df.iloc[raw_idx-1]
            prev_5 = df.iloc[max(0, raw_idx-5)]
            prev_10 = df.iloc[max(0, raw_idx-10)]
            
            # 1. ê¼¬ë¦¬% ì •ë°€ ê³„ì‚°
            high_p, low_p, close_p, open_p = row['High'], row['Low'], row['Close'], row['Open']
            body_max = max(open_p, close_p)
            t_pct = int((high_p - body_max) / (high_p - low_p) * 100) if high_p != low_p else 0

            # 2. ê¸°ì¡´ í•µì‹¬ ì „ìˆ  ì‹ í˜¸ íŒì •
            is_cloud_brk = prev['Close'] <= prev['Cloud_Top'] and close_p > row['Cloud_Top']
            is_kijun_sup = close_p > row['Kijun_sen'] and prev['Close'] <= prev['Kijun_sen']
            is_diamond = is_cloud_brk and is_kijun_sup
            
            is_super_squeeze = row['BB20_Width'] < 10 and row['BB40_Width'] < 15
            is_yeok_mae_old = close_p > row['MA112'] and prev['Close'] <= row['MA112']
            is_vol_power = row['Volume'] > row['VMA20'] * 2.5

            # ğŸ’¡ ì—­ë§¤ê³µíŒŒ 7ê°€ì§€ ì¡°ê±´ ì²´í¬
            yeok_1_ma_aligned = (row['MA5'] > row['MA20']) and (row['MA20'] > row['MA60'])
            yeok_2_ma_converged = row['MA_Convergence'] <= 3.0
            yeok_3_bb40_squeeze = row['BB40_Width'] <= 10.0
            yeok_4_red_candle = close_p < open_p
            day_change = ((close_p - prev['Close']) / prev['Close']) * 100
            yeok_5_pullback = -5.0 <= day_change <= -1.0
            yeok_6_volume_surge = row['Volume'] >= row['VMA5'] * 1.5
            yeok_7_ma5_support = close_p >= row['MA5'] * 0.97
            
            # ğŸ’¡ ë§¤ì§‘ 5ê°€ì§€ ì¡°ê±´ ì²´í¬
            acc_1_obv_rising = (row['OBV'] > prev_5['OBV']) and (row['OBV'] > prev_10['OBV'])
            acc_2_box_range = row['Box_Range'] <= 1.15
            acc_3_macd_golden = row['MACD'] > row['MACD_Signal']
            acc_4_rsi_healthy = 40 <= row['RSI'] <= 70
            acc_5_sto_golden = row['Sto_K'] > row['Sto_D']

            # 3. ì ìˆ˜ ì‚°ì¶œ ë° íƒœê·¸ ë¶€ì—¬
            s_score = 100
            tags = []
            
            # ê¸°ì¡´ ì‹œê·¸ë„ë“¤
            if is_diamond:
                s_score += 150
                tags.append("ğŸ’ë‹¤ì´ì•„ëª¬ë“œ")
                if t_pct < 10:
                    s_score += 50
                    tags.append("ğŸ”¥í­ë°œì§ì „")
            elif is_cloud_brk:
                s_score += 40
                tags.append("â˜ï¸êµ¬ë¦„ëŒíŒŒ")

            if is_yeok_mae_old: 
                s_score += 40
                tags.append("ğŸ†ì—­ë§¤ê³µíŒŒ")
                
            if is_super_squeeze: 
                s_score += 40
                tags.append("ğŸ”‹ì´ˆê°•ë ¥ì‘ì¶•")
                
            if is_vol_power: 
                s_score += 30
                tags.append("âš¡ê±°ë˜í­ë°œ")
            
            # ğŸ’¡ ì—­ë§¤ê³µíŒŒ ì™„ì „ì²´ ì²´í¬
            yeok_mae_count = sum([yeok_1_ma_aligned, yeok_2_ma_converged, yeok_3_bb40_squeeze,
                                 yeok_4_red_candle, yeok_5_pullback, yeok_6_volume_surge, yeok_7_ma5_support])
            
            if yeok_mae_count == 7:
                s_score += 100
                tags.append("ğŸ¯ì—­ë§¤ê³µíŒŒì™„ì „ì²´")
            elif yeok_mae_count >= 5:
                s_score += 50
                tags.append("ğŸ¯ì—­ë§¤ê³µíŒŒê°•")
            elif yeok_mae_count >= 3:
                s_score += 20
                tags.append("ğŸ¯ì—­ë§¤ê³µíŒŒì•½")
            
            # ì„¸ë¶€ íƒœê·¸
            if yeok_1_ma_aligned and yeok_2_ma_converged:
                tags.append("ğŸ“ì´í‰ìˆ˜ë ´")
            if yeok_3_bb40_squeeze:
                tags.append("ğŸ”‹ë°´ë“œ(40)")
            
            # ğŸ’¡ ë§¤ì§‘ ì‹œê·¸ë„ ì²´í¬
            acc_count = sum([acc_1_obv_rising, acc_2_box_range, acc_3_macd_golden,
                           acc_4_rsi_healthy, acc_5_sto_golden])
            
            if acc_count >= 4:
                s_score += 60
                tags.append("ğŸ‹ì„¸ë ¥ë§¤ì§‘")
            elif acc_count >= 3:
                s_score += 30
                tags.append("ğŸ‹ë§¤ì§‘ì§•í›„")
                
            if acc_1_obv_rising:
                tags.append("ğŸ“ŠOBVìƒìŠ¹")

            # ê¸°ì¡´ ê°ì  ë¡œì§
            if t_pct > 40:
                s_score -= 25
                tags.append("âš ï¸ìœ—ê¼¬ë¦¬")

            # ê¸°ìƒë„ ê°ì 
            storm_count = sum([1 for m in ['ixic', 'sp500'] if row[f'{m}_close'] <= row[f'{m}_ma5']])
            s_score -= (storm_count * 20)
            s_score -= max(0, int((row['Disparity']-108)*5)) 
            
            if not tags: continue

            # 4. ğŸ’¡ ìˆ˜ìµë¥  ê²€ì¦ ë°ì´í„° ìƒì„± (ìµœê³ /ìµœì € ì¶”ê°€)
            h_df = df.iloc[raw_idx+1:]
            
            if not h_df.empty:
                max_r = ((h_df['High'].max() - close_p) / close_p) * 100
                min_r = ((h_df['Low'].min() - close_p) / close_p) * 100
                
                # ğŸ’¡ ì˜¤ëŠ˜ì´ë©´ í˜„ì¬ê°€ = ì˜¤ëŠ˜ ì¢…ê°€, ì•„ë‹ˆë©´ í•´ë‹¹ ì‹œì ì˜ ë§ˆì§€ë§‰ ì¢…ê°€
                is_today = (len(h_df) == 0)  # ë³´ìœ ì¼ 0ì´ë©´ ì˜¤ëŠ˜
                current_price = today_price if not is_today else close_p
            else:
                max_r = 0
                min_r = 0
                current_price = close_p

            hits.append({
                'ë‚ ì§œ': curr_idx.strftime('%Y-%m-%d'),
                'ê¸°ìƒ': "â˜€ï¸" * (2-storm_count) + "ğŸŒªï¸" * storm_count,
                'ì•ˆì „ì ìˆ˜': int(max(0, s_score + whale_score)),
                'ì¢…ëª©': name,
                'ë§¤ì…ê°€': int(close_p),
                'í˜„ì¬ê°€': int(current_price),
                'ê¼¬ë¦¬%': t_pct,
                'ì´ê²©': int(row['Disparity']),
                'BB40': f"{row['BB40_Width']:.1f}",
                'MAìˆ˜ë ´': f"{row['MA_Convergence']:.1f}",
                'ì—­ë§¤': f"{yeok_mae_count}/7",
                'ë§¤ì§‘': f"{acc_count}/5",
                'ìµœê³ ìˆ˜ìµë¥ %': f"{max_r:+.1f}%",
                'ìµœì €ìˆ˜ìµë¥ %': f"{min_r:+.1f}%",
                'ìµœê³ ìˆ˜ìµë¥ _raw': max_r,
                'ìµœì €ìˆ˜ìµë¥ _raw': min_r,
                'êµ¬ë¶„': " ".join(tags),
                'ë³´ìœ ì¼': len(h_df)
            })
        return hits
    except: 
        return []

# ---------------------------------------------------------
# ğŸ’¾ [ì—‘ì…€ ì €ì¥] ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª© ì €ì¥
# ---------------------------------------------------------
def save_today_recommendations(df_today, recommendation_info):
    """ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª©ì„ ì—‘ì…€ë¡œ ì €ì¥"""
    try:
        filename = f"ì¶”ì²œì¢…ëª©_{TODAY_STR}.xlsx"
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # ì‹œíŠ¸1: ì˜¤ëŠ˜ì˜ ì¶”ì²œ ì¢…ëª©
            df_today.to_excel(writer, sheet_name='ì˜¤ëŠ˜ì˜_ì¶”ì²œ', index=False)
            
            # ì‹œíŠ¸2: ì¶”ì²œ ì •ë³´
            if recommendation_info:
                rec_df = pd.DataFrame([recommendation_info])
                rec_df.to_excel(writer, sheet_name='ì¶”ì²œ_íŒ¨í„´_ì •ë³´', index=False)
        
        print(f"\nğŸ’¾ ì—‘ì…€ ì €ì¥ ì™„ë£Œ: {filename}")
        return filename
    except Exception as e:
        print(f"\nâŒ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

# =================================================
# ğŸš€ [ì‹¤í–‰] ë©”ì¸ ì»¨íŠ¸ë¡¤ëŸ¬ (ìˆ˜ì • ë²„ì „)
# =================================================
if __name__ == "__main__":
    print(f"ğŸ“¡ [Ver 36.7 êµ¬ê¸€ì‹œíŠ¸ ê°•í™”] {TODAY_STR} ì „ìˆ  ì‚¬ë ¹ë¶€ í†µí•© ê°€ë™...")

    # 1. ë§¤í¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
    m_ndx = get_safe_macro('^IXIC', 'ë‚˜ìŠ¤ë‹¥')
    m_sp5 = get_safe_macro('^GSPC', 'S&P500')
    m_vix = get_safe_macro('^VIX', 'VIXê³µí¬')
    m_fx  = get_safe_macro('USD/KRW', 'ë‹¬ëŸ¬í™˜ìœ¨')
    
    kospi_supply = get_index_investor_data('KOSPI')
    macro_status = {'nasdaq': m_ndx, 'sp500': m_sp5, 'vix': m_vix, 'fx': m_fx, 'kospi': kospi_supply}

    print("\n" + "ğŸŒ " * 5 + "[ ê¸€ë¡œë²Œ ì‚¬ë ¹ë¶€ í†µí•© ê´€ì œ ì„¼í„° ]" + " ğŸŒ" * 5)
    print(f"ğŸ‡ºğŸ‡¸ {m_ndx['text']} | {m_sp5['text']} | âš ï¸ {m_vix['text']}")
    print(f"ğŸ’µ {m_fx['text']} | ğŸ‡°ğŸ‡· KOSPI ìˆ˜ê¸‰: {kospi_supply}")
    print("=" * 115)

    # 2. ì „ ì¢…ëª© ë¦¬ìŠ¤íŒ… ë° ê¸°ìƒë„ ì¤€ë¹„
    df_krx = fdr.StockListing('KRX')
    target_stocks = df_krx.sort_values(by='Amount', ascending=False).head(TOP_N)
    weather_data = prepare_historical_weather()
    
    # 3. ì „ìˆ  ìŠ¤ìº” (ë©€í‹°ìŠ¤ë ˆë”©)
    all_hits = []
    print(f"ğŸ” ì´ {len(target_stocks)}ê°œ ì¢…ëª© ğŸ’ë‹¤ì´ì•„ëª¬ë“œ & ğŸ¯ì—­ë§¤ê³µíŒŒ ë ˆì´ë” ê°€ë™...")
    with ThreadPoolExecutor(max_workers=15) as executor:
        results = list(executor.map(
            lambda p: analyze_final(p[0], p[1], weather_data), 
            zip(target_stocks['Code'], target_stocks['Name'])
        ))
        for r in results:
            if r: all_hits.extend(r)

    if all_hits:
         # 1. ì›ì¬ë£Œ(all_hits)ë¥¼ ì—°êµ¬ì†Œ(DNA_Analyzer)ë¡œ ì†¡ë¶€
        print("ğŸ§¬ [DNA Trace-Back] ì„±ê³µ ìœ ì „ì ì—­ì¶”ì  ê°€ë™...")
        dna_results = analyze_dna_sequences(all_hits)
    
        # 2. ê°€ì¥ ìŠ¹ë¥  ë†’ì€ íŒ¨í„´ ë­í‚¹ ì¶”ì¶œ
        top_patterns = find_winning_pattern(dna_results)

        df_total = pd.DataFrame(all_hits)
        
        # í†µê³„ ê³„ì‚° (ìƒìœ„ 5ê°œ ì¶”ì²œ ì •ë³´ í¬í•¨)
        stats_df, top_recommendations = calculate_strategy_stats(all_hits)
        
        # 4. ê²°ê³¼ ë¶„ë¥˜
        today = df_total[df_total['ë³´ìœ ì¼'] == 0].sort_values(by='ì•ˆì „ì ìˆ˜', ascending=False)
        
        # ì¶”ì²œ íŒ¨í„´ DataFrame ìƒì„±
        if top_recommendations:
            recommendation_df = pd.DataFrame(top_recommendations)
            recommendation_df['ë‚ ì§œ'] = TODAY_STR
            recommendation_df = recommendation_df[['ë‚ ì§œ', 'ìˆœìœ„', 'íŒ¨í„´', 'íƒ€ìœ¨', 'í‰ê· ìˆ˜ìµ', 'ê¸°ëŒ€ê°’', 'ê±´ìˆ˜', 'ì‹ ë¢°ë„']]
        else:
            recommendation_df = pd.DataFrame()
        
        # ğŸ’¡ ì¶”ì²œ íŒ¨í„´ ì¶œë ¥ (ì—¬ëŸ¬ ê°œ)
        if top_recommendations:
            print("\n" + "ğŸ† " * 10 + "[ AI ì¶”ì²œ TOP 5 íŒ¨í„´ ]" + " ğŸ†" * 10)
            for i, rec in enumerate(top_recommendations, 1):
                medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}ìœ„"
                print(f"\n{medal} [{rec['íŒ¨í„´']}]")
                print(f"   ğŸ“Š íƒ€ìœ¨ {rec['íƒ€ìœ¨']}% | í‰ê· ìˆ˜ìµ {rec['í‰ê· ìˆ˜ìµ']}% | ê¸°ëŒ€ê°’ {rec['ê¸°ëŒ€ê°’']} | ê±´ìˆ˜ {rec['ê±´ìˆ˜']}ê±´")
                print(f"   {rec['ì‹ ë¢°ë„']}")
            print("=" * 100)
            
        if not top_patterns.empty:
    # ğŸ’¡ 1. 'top_patterns' ë°ì´í„°í”„ë ˆì„ì—ì„œ 1ìˆœìœ„ íŒ¨í„´ ë¬¸ìì—´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    # DNA_ì‹œí€€ìŠ¤ ì»¬ëŸ¼ì˜ ì²« ë²ˆì§¸ í–‰(iloc[0])ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            best_pattern_str = top_patterns.iloc[0]['DNA_ì‹œí€€ìŠ¤']
    
    # ğŸ’¡ 2. íŒ¨í„´ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ(ì˜ˆ: 'ë§¤ì§‘ë´‰')ë§Œ ë–¼ì–´ë‚´ì–´ ì˜¤ëŠ˜ ì¢…ëª©ì„ í•„í„°ë§í•©ë‹ˆë‹¤.
    # ì‚¬ë ¹ê´€ë‹˜ì´ ì‘ì„±í•˜ì‹  split logicì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            target_tag = best_pattern_str.split(' â” ')[0] # 'â”' ê¸°í˜¸ ê¸°ì¤€ ì²« íƒœê·¸ ì¶”ì¶œ
    
            print(f"ğŸ¯ [DNA í•„í„°] ì˜¤ëŠ˜ì˜ 1ìˆœìœ„ íƒ€ê²Ÿ íŒ¨í„´: {target_tag}")
    
    # ğŸ’¡ 3. ì˜¤ëŠ˜ ë°ì´í„°(today)ì—ì„œ í•´ë‹¹ íƒœê·¸ê°€ í¬í•¨ëœ ì¢…ëª©ë§Œ ì¶”ì¶œ
            recommended_today = today[today['êµ¬ë¶„'].str.contains(target_tag, na=False)]
        else:
            print("âš ï¸ [DNA í•„í„°] ìœ íš¨í•œ ì„±ê³µ íŒ¨í„´ì´ ì—†ì–´ ì „ì²´ ì¢…ëª©ì„ ìœ ì§€í•©ë‹ˆë‹¤.")
            recommended_today = today.copy()

            # 1ìœ„ íŒ¨í„´ì´ í¬í•¨ëœ ì˜¤ëŠ˜ì˜ ì¢…ëª© í•„í„°ë§
            top_pattern = top_recommendations[0]['íŒ¨í„´']
            recommended_today = today[today['êµ¬ë¶„'].str.contains(top_pattern.split(' + ')[0], na=False)]
            if not recommended_today.empty:
                print(f"\nâœ¨ ì˜¤ëŠ˜ì˜ '{top_pattern}' íŒ¨í„´ ì¢…ëª©")
                print(recommended_today[['ì¢…ëª©', 'ì•ˆì „ì ìˆ˜', 'ë§¤ì…ê°€', 'ì—­ë§¤', 'ë§¤ì§‘', 'êµ¬ë¶„']].head(10))
        
        # ğŸ’¡ í†µí•©: ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª© (ì—­ë§¤ê³µíŒŒ í¬í•¨, ì•ˆì „ì ìˆ˜ ìˆœ)
        print("\n" + "ğŸ¯ " * 10 + "[ ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª© TOP 50 ]" + " ğŸ¯" * 10)
        print("(ì—­ë§¤ê³µíŒŒ, ë‹¤ì´ì•„ëª¬ë“œ, ì„¸ë ¥ë§¤ì§‘ ë“± ëª¨ë“  íŒ¨í„´ í¬í•¨ / ì•ˆì „ì ìˆ˜ ìˆœ)")
        print("=" * 120)
        
        if not today.empty:
            display_cols = ['ì¢…ëª©', 'ì•ˆì „ì ìˆ˜', 'ë§¤ì…ê°€', 'í˜„ì¬ê°€', 'ê¼¬ë¦¬%', 'ì—­ë§¤', 'ë§¤ì§‘', 'BB40', 'MAìˆ˜ë ´', 'êµ¬ë¶„']
            print(today[display_cols].head(50))
            
            # ğŸ’¡ íŒ¨í„´ë³„ ì§‘ê³„ (ì°¸ê³ ìš©)
            diamond_count = len(today[today['êµ¬ë¶„'].str.contains('ë‹¤ì´ì•„ëª¬ë“œ', na=False)])
            yeok_complete = len(today[today['êµ¬ë¶„'].str.contains('ì—­ë§¤ê³µíŒŒì™„ì „ì²´', na=False)])
            yeok_strong = len(today[today['êµ¬ë¶„'].str.contains('ì—­ë§¤ê³µíŒŒê°•', na=False)])
            accumulation = len(today[today['êµ¬ë¶„'].str.contains('ì„¸ë ¥ë§¤ì§‘', na=False)])
            
            print("\nğŸ“Š [ ì˜¤ëŠ˜ì˜ íŒ¨í„´ ë¶„í¬ ]")
            print(f"   ğŸ’ ë‹¤ì´ì•„ëª¬ë“œ: {diamond_count}ê°œ")
            print(f"   ğŸ¯ ì—­ë§¤ê³µíŒŒ ì™„ì „ì²´: {yeok_complete}ê°œ")
            print(f"   ğŸ¯ ì—­ë§¤ê³µíŒŒ ê°•: {yeok_strong}ê°œ")
            print(f"   ğŸ‹ ì„¸ë ¥ë§¤ì§‘: {accumulation}ê°œ")
            print(f"   ğŸ“ˆ ì „ì²´ ì¶”ì²œì¢…ëª©: {len(today)}ê°œ")
        else:
            print("ì˜¤ëŠ˜ì€ ì¶”ì²œí•  ë§Œí•œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

        print("\n" + "ğŸ“Š [ì „ëµë³„ í†µê³„ (ê³¼ê±° 30ì¼)] " + "="*70)
        if not stats_df.empty:
            print(stats_df.head(20))

        # 5. êµ¬ê¸€ ì‹œíŠ¸ ì „ì†¡
        try:
            update_commander_dashboard(
                df_total,  # ë©”ì¸ ì‹œíŠ¸: ì „ì²´ 30ì¼ ë°ì´í„°
                macro_status, 
                "ì‚¬ë ¹ë¶€_í†µí•©_ìƒí™©íŒ", 
                stats_df,
                today,  # ì˜¤ëŠ˜ì˜_ì¶”ì²œì¢…ëª© íƒ­: ì˜¤ëŠ˜ë§Œ (ëª¨ë“  íŒ¨í„´ í†µí•©)
                ai_recommendation=dna_results  # AI_ì¶”ì²œíŒ¨í„´ íƒ­: TOP 5
            )
            print("\nâœ… êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì„±ê³µ!")
            print("   ğŸ“‹ ë©”ì¸ ì‹œíŠ¸: ì „ì²´ 30ì¼ ê²€ì¦ ë°ì´í„°")
            print("   ğŸ¯ ì˜¤ëŠ˜ì˜_ì¶”ì²œì¢…ëª© íƒ­: ì˜¤ëŠ˜ ì‹ í˜¸ë§Œ (TOP 50, ëª¨ë“  íŒ¨í„´ í†µí•©)")
            print("   ğŸ† AI_ì¶”ì²œíŒ¨í„´ íƒ­: TOP 5 íŒ¨í„´ ë¶„ì„")
        except Exception as e:
            print(f"\nâŒ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    else:
        print("\nâš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")