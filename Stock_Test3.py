# ------------------------------------------------------------------
# ğŸ’ [Ultimate Masterpiece] ì „ì²œí›„ AI ì „ëµ ì‚¬ë ¹ë¶€ (Ver 36.7 ì—‘ì…€ì €ì¥+ì¶”ì²œì‹œìŠ¤í…œ)
# ------------------------------------------------------------------
import FinanceDataReader as fdr
import os, re, time, pytz
from pykrx import stock
import pandas as pd
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
import warnings
import requests
from bs4 import BeautifulSoup
from DNA_Analyzer import analyze_dna_sequences, find_winning_pattern
from tactics_engine import get_global_and_leader_status, analyze_all_narratives, get_dynamic_sector_leaders, calculate_dante_symmetry
import traceback

from pykrx import stock
import pandas as pd
from datetime import datetime

# ğŸ‘‡ êµ¬ê¸€ ì‹œíŠ¸ ë§¤ë‹ˆì € ì—°ê²° (íŒŒì¼ëª… í™•ì¸ í•„ìˆ˜)
try:
    from google_sheet_managerEx import update_commander_dashboard
except ImportError:
    def update_commander_dashboard(*args, **kwargs): print("âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ëª¨ë“ˆ ì—°ê²° ì‹¤íŒ¨")

warnings.filterwarnings('ignore')

# =================================================
# âš™ï¸ [1. ì„¤ì • ë° ê¸€ë¡œë²Œ ë³€ìˆ˜]
# =================================================
DNA_CHECK = False
SCAN_DAYS = 15       # ìµœê·¼ 30ì¼ ë‚´ íƒ€ì  ì „ìˆ˜ ì¡°ì‚¬
TOP_N = 2500         # ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª© ìˆ˜ (í•„ìš”ì‹œ 2500ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥)
KST = pytz.timezone('Asia/Seoul')
NOW = datetime.now(KST)
TODAY_STR = NOW.strftime('%Y-%m-%d')
START_DATE = (datetime.now() - timedelta(days=600)).strftime('%Y-%m-%d')
END_DATE_STR = datetime.now().strftime('%Y%m%d')

print(f"ğŸ“¡ [Ver 36.7 ì—‘ì…€ì €ì¥+ì¶”ì²œ] ì‚¬ë ¹ë¶€ ë¬´ê²°ì„± í†µí•© ê°€ë™... ğŸ’ë‹¤ì´ì•„ëª¬ë“œ & ğŸ“Šë³µí•©í†µê³„ ì—”ì§„ íƒ‘ì¬")

def get_stock_sector(ticker, sector_map):
    """
    ê¸°ì¡´ì— ìˆ˜ì§‘ëœ ì„¹í„° ë§ˆìŠ¤í„° ë§µì—ì„œ ì¢…ëª©ì˜ ì—…ì¢…ì„ íŒë…í•©ë‹ˆë‹¤.
    """
    # 1. ë§ˆìŠ¤í„° ë§µì—ì„œ í•´ë‹¹ ì¢…ëª©ì˜ ì—…ì¢…ëª… ì¶”ì¶œ
    raw_sector = sector_map.get(ticker, "ì¼ë°˜")
    
    # 2. í‚¤ì›Œë“œ ë§¤ì¹­ì„ í†µí•œ ì„¹í„° ì •ê·œí™” (ëŒ€ì¥ì£¼ ë™ê¸°í™”ìš©)
    if any(k in raw_sector for k in ['ë°˜ë„ì²´', 'ITë¶€í’ˆ', 'ì¥ë¹„']): 
        return "ë°˜ë„ì²´"
    if any(k in raw_sector for k in ['ì œì•½', 'ë°”ì´ì˜¤', 'ì˜ë£Œê¸°ê¸°', 'ìƒë¬¼']): 
        return "ë°”ì´ì˜¤"
    if any(k in raw_sector for k in ['ì „ê¸°ì°¨', 'ë°°í„°ë¦¬', 'ì—ë„ˆì§€', 'ì¶•ì „ì§€']): 
        return "2ì°¨ì „ì§€"
    
    return "ì¼ë°˜"

def get_commander_market_cap():
    """
    ì´ë¦„ê³¼ ì½”ë“œ, ì–´ë–¤ ê²ƒìœ¼ë¡œë„ ì²´ê¸‰ì„ ì¦‰ì‹œ íŒë…í•  ìˆ˜ ìˆëŠ” ë§ˆìŠ¤í„° ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("ğŸ“¡ [Cap-Scanner] ì „ ì¢…ëª© ë§ˆìŠ¤í„° ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    try:
        now = datetime.now().strftime("%Y%m%d")
        # 1. ì‹œê°€ì´ì•¡ ë°ì´í„° (ì¸ë±ìŠ¤ê°€ ì¢…ëª©ì½”ë“œ)
        df_cap = stock.get_market_cap(now, market="ALL")
        
        # 2. ì¢…ëª©ëª… ë°ì´í„° (ì¢…ëª©ì½”ë“œ, ì¢…ëª©ëª… ë§¤í•‘)
        df_desc = stock.get_market_net_purchases_of_equities_by_ticker(now, now, "ALL") # ì´ë¦„ ê°€ì ¸ì˜¤ê¸°ìš© íŒ
        # ë” í™•ì‹¤í•œ ì´ë¦„-ì½”ë“œ ë§¤í•‘
        tickers = stock.get_market_ticker_list(now, market="ALL")
        names = [stock.get_market_ticker_name(t) for t in tickers]
        df_name = pd.DataFrame({'Code': tickers, 'Name': names}).set_index('Code')

        # 3. ë°ì´í„° ë³‘í•©
        master_df = df_cap.join(df_name)
        
        # ğŸ’¡ [í•µì‹¬] ë‘ ê°€ì§€ íƒ€ì…ì˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        code_to_cap = master_df['ì‹œê°€ì´ì•¡'].to_dict()
        name_to_cap = master_df.set_index('Name')['ì‹œê°€ì´ì•¡'].to_dict()

        print(f"âœ… [Cap-Scanner] ë§ˆìŠ¤í„° ë°ì´í„° {len(code_to_cap)}ê±´ ë¡œë“œ ì™„ë£Œ.")
        return {"code": code_to_cap, "name": name_to_cap}
    except Exception as e:
        print(f"âŒ [Cap-Scanner] ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return {"code": {}, "name": {}}

def assign_tier(name, code, master_map):
    """
    ì½”ë“œ ìš°ì„ , ì´ë¦„ ì°¨ì„ ìœ¼ë¡œ ì²´ê¸‰ì„ ê²°ì •í•©ë‹ˆë‹¤.
    """
    # 1. ì½”ë“œë¡œ ì¡°íšŒ ì‹œë„
    cap = master_map['code'].get(code, 0)
    
    # 2. ì½”ë“œë¡œ ì‹¤íŒ¨ ì‹œ ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ ì‹œë„
    if cap == 0:
        cap = master_map['name'].get(name, 0)
    
    # 3. ì²´ê¸‰ ê²°ì •
    if cap >= 1_000_000_000_000: return "ğŸ‘‘HEAVY", cap
    if cap >= 200_000_000_000: return "âš”ï¸MIDDLE", cap
    if cap > 0: return "ğŸš€LIGHT", cap
    
    return "â“ë¯¸í™•ì¸", 0

# ---------------------------------------------------------
# ğŸŒ [ë§¤í¬ë¡œ ì—”ì§„] ê¸€ë¡œë²Œ ì§€ìˆ˜ ë° ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘
# ---------------------------------------------------------
def get_safe_macro(symbol, name):
    try:
        df = fdr.DataReader(symbol, start=(datetime.now() - timedelta(days=15)).strftime('%Y-%m-%d'))
        curr, prev = df.iloc[-1]['Close'], df.iloc[-2]['Close']
        ma5 = df['Close'].tail(5).mean()
        chg = ((curr - prev) / prev) * 100
        status = "â˜€ï¸ë§‘ìŒ" if curr > ma5 else "ğŸŒªï¸í­í’ìš°"
        if "VIX" in name: status = "â˜€ï¸ì•ˆì •" if curr < ma5 else "ğŸŒªï¸ìœ„í—˜"
        return {"val": curr, "chg": chg, "status": status, "text": f"{name}: {curr:,.2f}({chg:+.2f}%) {status}"}
    except: return {"status": "â˜ï¸ë¶ˆëª…", "text": f"{name}: ì—°ê²°ì‹¤íŒ¨"}

def get_index_investor_data(market_name):
    try:
        df = stock.get_market_net_purchases_of_equities(END_DATE_STR, END_DATE_STR, market_name)
        if df.empty:
            prev_day = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
            df = stock.get_market_net_purchases_of_equities(prev_day, prev_day, market_name)
        total = df.sum()
        return f"ê°œì¸ {total['ê°œì¸']:+,.0f} | ì™¸ì¸ {total['ì™¸êµ­ì¸']:+,.0f} | ê¸°ê´€ {total['ê¸°ê´€í•©ê³„']:+,.0f}"
    except: return "ë°ì´í„° ìˆ˜ì‹  ì¤‘..."

def prepare_historical_weather():
    """ì—­ì‚¬ì  ê¸°ìƒë„ë¥¼ ì‘ì„±í•˜ì—¬ analyze_finalì— ë³´ê¸‰í•©ë‹ˆë‹¤."""
    start_point = (datetime.now() - timedelta(days=600)).strftime('%Y-%m-%d')
    ndx = fdr.DataReader('^IXIC', start=start_point)[['Close']]
    sp5 = fdr.DataReader('^GSPC', start=start_point)[['Close']]
    ndx['ixic_ma5'] = ndx['Close'].rolling(5).mean()
    sp5['sp500_ma5'] = sp5['Close'].rolling(5).mean()
    weather_df = pd.concat([
        ndx.rename(columns={'Close': 'ixic_close'}),
        sp5.rename(columns={'Close': 'sp500_close'})
    ], axis=1).fillna(method='ffill')
    return weather_df

# ---------------------------------------------------------
# ğŸ“Š [ì „ìˆ  í†µê³„] ë³µí•© ì „ìˆ  í†µê³„ ì—”ì§„ (ìƒìœ„ 5ê°œ ì¶”ì²œ)
# ---------------------------------------------------------
def calculate_strategy_stats(all_hits):
    past_hits = [h for h in all_hits if h['ë³´ìœ ì¼'] > 0]
    if not past_hits: return pd.DataFrame(), None
    
    stats = {}
    for h in past_hits:
        raw_tags = h['êµ¬ë¶„'].split()
        if not raw_tags: continue
        
        # ê°œë³„ íƒœê·¸ ë° ë³µí•© íƒœê·¸ ìƒì„±
        combos = []
        for tag in raw_tags:
            combos.append(tag)
        
        # 2ê°œ ì¡°í•©
        if len(raw_tags) >= 2:
            sorted_tags = sorted(raw_tags)
            for i in range(len(sorted_tags)):
                for j in range(i+1, len(sorted_tags)):
                    combos.append(f"{sorted_tags[i]} + {sorted_tags[j]}")
        
        # ì „ì²´ ì¡°í•©
        if len(raw_tags) > 1:
            combos.append(" + ".join(sorted(raw_tags)))
        
        for strategy in set(combos):
            if strategy not in stats: 
                stats[strategy] = {'total': 0, 'hits': 0, 'yields': [], 'min_yields': []}
            stats[strategy]['total'] += 1
            if h['ìµœê³ ìˆ˜ìµë¥ _raw'] >= 3.5: stats[strategy]['hits'] += 1
            stats[strategy]['yields'].append(h['ìµœê³ ìˆ˜ìµë¥ _raw'])
            stats[strategy]['min_yields'].append(h['ìµœì €ìˆ˜ìµë¥ _raw'])

    report_data = []
    for strategy, data in stats.items():
        avg_max_yield = sum(data['yields']) / data['total']
        avg_min_yield = sum(data['min_yields']) / data['total']
        hit_rate = (data['hits'] / data['total']) * 100
        
        # ê¸°ëŒ€ê°’ ê³„ì‚° (í™•ë¥  * ìˆ˜ìµë¥ )
        expected_value = (hit_rate / 100) * avg_max_yield
        
        report_data.append({
            'ì „ëµëª…': strategy, 
            'í¬ì°©ê±´ìˆ˜': data['total'], 
            'íƒ€ìœ¨(ìŠ¹ë¥ )': round(hit_rate, 1), 
            'í‰ê· ìµœê³ ìˆ˜ìµ': round(avg_max_yield, 1),
            'í‰ê· ìµœì €ìˆ˜ìµ': round(avg_min_yield, 1),
            'ê¸°ëŒ€ê°’': round(expected_value, 2)
        })
    
    df_stats = pd.DataFrame(report_data).sort_values(
        by=['ê¸°ëŒ€ê°’', 'í‰ê· ìµœê³ ìˆ˜ìµ', 'íƒ€ìœ¨(ìŠ¹ë¥ )'], 
        ascending=False
    )
    
    # ğŸ’¡ ìƒìœ„ 3~5ê°œ íŒ¨í„´ ì¶”ì²œ
    top_recommendations = []
    if len(df_stats) > 0:
        # ìµœì†Œ 5ê±´ ì´ìƒ ë°ì´í„° ìˆëŠ” íŒ¨í„´ ìš°ì„ 
        reliable_patterns = df_stats[df_stats['í¬ì°©ê±´ìˆ˜'] >= 5]
        
        if len(reliable_patterns) >= 3:
            # ì‹ ë¢°ë„ ë†’ì€ íŒ¨í„´ ì¤‘ ìƒìœ„ 5ê°œ
            top_5 = reliable_patterns.head(5)
            for idx, row in top_5.iterrows():
                top_recommendations.append({
                    'ìˆœìœ„': len(top_recommendations) + 1,
                    'íŒ¨í„´': row['ì „ëµëª…'],
                    'íƒ€ìœ¨': row['íƒ€ìœ¨(ìŠ¹ë¥ )'],
                    'í‰ê· ìˆ˜ìµ': row['í‰ê· ìµœê³ ìˆ˜ìµ'],
                    'ê¸°ëŒ€ê°’': row['ê¸°ëŒ€ê°’'],
                    'ê±´ìˆ˜': row['í¬ì°©ê±´ìˆ˜'],
                    'ì‹ ë¢°ë„': 'â­â­â­ ë†’ìŒ'
                })
        else:
            # ë°ì´í„° ë¶€ì¡±ì‹œ ì „ì²´ì—ì„œ ìƒìœ„ 5ê°œ
            top_5 = df_stats.head(5)
            for idx, row in top_5.iterrows():
                reliability = 'â­â­â­ ë†’ìŒ' if row['í¬ì°©ê±´ìˆ˜'] >= 5 else 'â­â­ ë³´í†µ' if row['í¬ì°©ê±´ìˆ˜'] >= 3 else 'â­ ì£¼ì˜'
                top_recommendations.append({
                    'ìˆœìœ„': len(top_recommendations) + 1,
                    'íŒ¨í„´': row['ì „ëµëª…'],
                    'íƒ€ìœ¨': row['íƒ€ìœ¨(ìŠ¹ë¥ )'],
                    'í‰ê· ìˆ˜ìµ': row['í‰ê· ìµœê³ ìˆ˜ìµ'],
                    'ê¸°ëŒ€ê°’': row['ê¸°ëŒ€ê°’'],
                    'ê±´ìˆ˜': row['í¬ì°©ê±´ìˆ˜'],
                    'ì‹ ë¢°ë„': reliability
                })
    
    return df_stats, top_recommendations

# ---------------------------------------------------------
# ğŸ“ˆ [ë°ì´í„°] ë§ˆìŠ¤í„° ì§€í‘œ ì—”ì§„ (Ver 36.7)
# ---------------------------------------------------------
def get_indicators(df):
    df = df.copy()
    count = len(df)
    
    # ë‹¨í…Œ ì¥ê¸°ì„  í¬í•¨ ì´í‰ì„ 
    for n in [5, 20, 40, 60, 112, 224]:
        df[f'MA{n}'] = df['Close'].rolling(window=min(count, n)).mean()
        df[f'VMA{n}'] = df['Volume'].rolling(window=min(count, n)).mean()
    
    # 20/40ì¼ BB Width (ì´ì¤‘ ì‘ì¶•)
    std20 = df['Close'].rolling(20).std()
    df['BB_Upper'] = df['MA20'] + (std20 * 2)
    df['BB20_Width'] = (std20 * 4) / df['MA20'] * 100
    std40 = df['Close'].rolling(40).std()
    df['BB40_Upper'] = df['MA40'] + (std40 * 2)
    df['BB40_Lower'] = df['MA40'] - (std40 * 2)
    df['BB40_Width'] = (std40 * 4) / df['MA40'] * 100
    
    # ì´í‰ì„  ìˆ˜ë ´ë„ ê³„ì‚°
    df['MA_Convergence'] = abs(df['MA20'] - df['MA60']) / df['MA60'] * 100
    
    # ì¼ëª©ê· í˜•í‘œ
    df['Tenkan_sen'] = (df['High'].rolling(9).max() + df['Low'].rolling(9).min()) / 2
    df['Kijun_sen'] = (df['High'].rolling(26).max() + df['Low'].rolling(26).min()) / 2
    df['Span_A'] = ((df['Tenkan_sen'] + df['Kijun_sen']) / 2).shift(26)
    df['Span_B'] = ((df['High'].rolling(52).max() + df['Low'].rolling(52).min()) / 2).shift(26)
    df['Cloud_Top'] = df[['Span_A', 'Span_B']].max(axis=1)

    # ìŠ¤í† ìºìŠ¤í‹±
    l_min, h_max = df['Low'].rolling(12).min(), df['High'].rolling(12).max()
    df['Sto_K'] = ((df['Close'] - l_min) / (h_max - l_min)) * 100
    df['Sto_D'] = df['Sto_K'].rolling(5).mean()
    df['Sto_SD'] = df['Sto_D'].rolling(5).mean()
    
    # ADX
    high, low, close = df['High'], df['Low'], df['Close']
    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)
    df['ADX'] = ((abs((high-high.shift(1)).clip(lower=0).rolling(14).sum() - (low.shift(1)-low).clip(lower=0).rolling(14).sum()) / 
                ((high-high.shift(1)).clip(lower=0).rolling(14).sum() + (low.shift(1)-low).clip(lower=0).rolling(14).sum())) * 100).rolling(14).mean()
    
    # MACD
    ema12 = df['Close'].ewm(span=12).mean()
    ema26 = df['Close'].ewm(span=26).mean()
    df['MACD'] = ema12 - ema26
    df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']
    
    # OBV
    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
    df['OBV_Slope'] = (df['OBV'] - df['OBV'].shift(5)) / df['OBV'].shift(5).abs() * 100
    
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    
    df['Disparity'] = (df['Close'] / df['MA20']) * 100
    df['Box_Range'] = df['High'].rolling(10).max() / df['Low'].rolling(10).min()
    
    # ATR
    high, low, close = df['High'], df['Low'], df['Close']
    tr = pd.concat([
        high - low, 
        abs(high - close.shift(1)), 
        abs(low - close.shift(1))
    ], axis=1).max(axis=1)
    df['ATR'] = tr.rolling(14).mean()
    df['ATR_MA20'] = df['ATR'].rolling(20).mean()
    
    # MFI
    typical_price = (df['High'] + df['Low'] + df['Close']) / 3
    money_flow = typical_price * df['Volume']
    
    positive_flow = money_flow.where(typical_price > typical_price.shift(1), 0).rolling(14).sum()
    negative_flow = money_flow.where(typical_price < typical_price.shift(1), 0).rolling(14).sum()
    
    mfi_ratio = positive_flow / negative_flow
    df['MFI'] = 100 - (100 / (1 + mfi_ratio))
    df['MFI_Prev5'] = df['MFI'].shift(5)
    
    # ğŸ’¡ [ì‹ ê·œ] ìµœê·¼ Nì¼ ì§€ì†ì„± ì²´í¬ìš© ì»¬ëŸ¼ë“¤
    # ATRì´ í‰ê·  ì•„ë˜ì¸ ë‚  ì¹´ìš´íŠ¸ (ìµœê·¼ 10ì¼)
    df['ATR_Below_MA'] = (df['ATR'] < df['ATR_MA20']).astype(int)
    df['ATR_Below_Days'] = df['ATR_Below_MA'].rolling(10).sum()
    
    # MFI 50 ì´ìƒì¸ ë‚  ì¹´ìš´íŠ¸ (ìµœê·¼ 10ì¼)
    df['MFI_Above50'] = (df['MFI'] > 50).astype(int)
    df['MFI_Strong_Days'] = df['MFI_Above50'].rolling(10).sum()
    
    # MFI ìƒìŠ¹ ì¶”ì„¸ (10ì¼ ì „ë³´ë‹¤ ë†’ìŒ)
    df['MFI_10d_ago'] = df['MFI'].shift(10)
    
    # ë³¼ë¦°ì € %B
    df['BB40_PercentB'] = (df['Close'] - df['BB40_Lower']) / (df['BB40_Upper'] - df['BB40_Lower'])

    return df

# ---------------------------------------------------------
# ğŸ•µï¸â€â™‚ï¸ [ë¶„ì„] ì •ë°€ ë¶„ì„ ì—”ì§„ (Ver 36.7 ìµœì €ìˆ˜ìµë¥  ì¶”ê°€)
# ---------------------------------------------------------
def analyze_final(ticker, name, historical_indices, g_env, l_env, s_map):
    try:
        df = fdr.DataReader(ticker, start=START_DATE)
        if len(df) < 100: return []
        df = get_indicators(df)
        df = df.join(historical_indices, how='left').fillna(method='ffill')

        # 1. ë‚´ ì¢…ëª©ì˜ ì„¹í„° í™•ì¸
        my_sector = s_map.get(ticker, "ì¼ë°˜")
    
        # 2. ìš°ë¦¬ ì„¹í„° ëŒ€ì¥ì£¼ì˜ ìƒíƒœ í™•ì¸ (leader_status ë§µ í™œìš©)
        current_leader_condition = l_env.get(my_sector, "Normal")
    
        # 3. í™•ì‹  ì ìˆ˜ì— ë°˜ì˜
        l_score = 25 if current_leader_condition == "ğŸ”¥ê°•ì„¸" else 0
    
        # ğŸ•µï¸ ì‹ ê·œ ì¶”ê°€: ì„œì‚¬ ë¶„ì„ê¸° í˜¸ì¶œ
        #print(f"âœ… [ë³¸ì§„] ì„œì‚¬ ë¶„ì„ê¸° í˜¸ì¶œ : {name}")
        sector = get_stock_sector(ticker, sector_master_map) # ì„¹í„° íŒë… í•¨ìˆ˜ í•„ìš”
        grade, narrative, target, stop, conviction = analyze_all_narratives(
            df, name, my_sector, g_env, l_env
        )
        dante_data = calculate_dante_symmetry(df)
        
        if dante_data is None:
            dante_data_ratio = 0
            dante_data_mae_jip = 0

        # ğŸ’¡ ì˜¤ëŠ˜ì˜ í˜„ì¬ê°€ ì €ì¥ (ë‚˜ì¤‘ì— ì‚¬ìš©)
        today_price = df.iloc[-1]['Close']
        
        # ìµœì‹  ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘
        try:
            #print(f"âœ… [ë³¸ì§„] ìµœì‹  ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘")
            url = f"https://finance.naver.com/item/frgn.naver?code={ticker}"
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=5)
            res.encoding = 'euc-kr'
            supply_df = pd.read_html(res.text)[2].dropna()
            f_qty = int(str(supply_df.iloc[0]['ì™¸êµ­ì¸']).replace('.0','').replace(',',''))
            i_qty = int(str(supply_df.iloc[0]['ê¸°ê´€']).replace('.0','').replace(',',''))
            twin_b = (f_qty > 0 and i_qty > 0)
            whale_score = int(((f_qty + i_qty) * df.iloc[-1]['Close']) / 100000000)
        except:
            f_qty, i_qty, twin_b, whale_score = 0, 0, False, 0

        recent_df = df.tail(SCAN_DAYS)
        hits = []

        #print(f"âœ… [ë³¸ì§„] íŒ¨í„´ ì°¾ê¸°")
        for curr_idx, row in recent_df.iterrows():
            raw_idx = df.index.get_loc(curr_idx)
            if raw_idx < 100: continue
            prev = df.iloc[raw_idx-1]
            prev_5 = df.iloc[max(0, raw_idx-5)]
            prev_10 = df.iloc[max(0, raw_idx-10)]
            
            # 1. ê¼¬ë¦¬% ì •ë°€ ê³„ì‚°
            high_p, low_p, close_p, open_p = row['High'], row['Low'], row['Close'], row['Open']
            body_max = max(open_p, close_p)
            t_pct = int((high_p - body_max) / (high_p - low_p) * 100) if high_p != low_p else 0

            # 2. ê¸°ì¡´ í•µì‹¬ ì „ìˆ  ì‹ í˜¸ íŒì •
            is_cloud_brk = prev['Close'] <= prev['Cloud_Top'] and close_p > row['Cloud_Top']
            is_kijun_sup = close_p > row['Kijun_sen'] and prev['Close'] <= prev['Kijun_sen']
            is_diamond = is_cloud_brk and is_kijun_sup
            
            is_super_squeeze = row['BB20_Width'] < 10 and row['BB40_Width'] < 15
            is_yeok_mae_old = close_p > row['MA112'] and prev['Close'] <= row['MA112']
            is_vol_power = row['Volume'] > row['VMA20'] * 2.5

            # --- [ì—­ë§¤ê³µíŒŒ í†µí•© 7ë‹¨ê³„ ë¡œì§] ---
            # 1. [ì—­(é€†)] ì—­ë°°ì—´ ë°”ë‹¥ íƒˆì¶œ (5/20 ê³¨ë“ í¬ë¡œìŠ¤)
            # ì˜ë¯¸: í•˜ë½ì„ ë©ˆì¶”ê³  ë‹¨ê¸° ì¶”ì„¸ë¥¼ ëŒë¦¬ëŠ” ì²« ì‹ í˜¸
            is_yeok = (prev['MA5'] <= prev['MA20']) and (row['MA5'] > row['MA20'])

            # 2. [ë§¤(åŸ‹)] ì—ë„ˆì§€ ì‘ì¶• (ì´í‰ì„  ë°€ì§‘)
            # ì˜ë¯¸: 5, 20, 60ì¼ì„ ì´ 3% ì´ë‚´ë¡œ ëª¨ì—¬ ì—ë„ˆì§€ê°€ ì••ì¶•ëœ ìƒíƒœ
            is_mae = row['MA_Convergence'] <= 3.0

            # 3. [ê³µ(ç©º)] ê³µêµ¬ë¦¬ ëŒíŒŒ (MA112 ëŒíŒŒ) - ì‚¬ë ¹ê´€ë‹˜ì´ ì°¾ì•„ë‚¸ í•µì‹¬!
            # ì˜ë¯¸: 6ê°œì›” ì¥ê¸° ì €í•­ì„ (ê³µêµ¬ë¦¬)ì„ ì¢…ê°€ë¡œ ëš«ì–´ë²„ë¦¬ëŠ” ìˆœê°„
            is_gong = (close_p > row['MA112']) and (prev['Close'] <= row['MA112'])

            # 4. [íŒŒ(ç ´)] íŒŒë™ì˜ ì‹œì‘ (BB40 ìƒë‹¨ ëŒíŒŒ)
            # ì˜ë¯¸: ë³¼ë¦°ì €ë°´ë“œ ìƒë‹¨ì„ ëš«ê³  ë³€ë™ì„±ì´ ìœ„ë¡œ í„°ì§€ëŠ” ì‹œì 
            is_pa = (row['Close'] > row['BB40_Upper']) and (prev['Close'] <= row['BB40_Upper'])

            # 5. [í™”ë ¥] ê±°ë˜ëŸ‰ ë™ë°˜ (VMA5 ëŒ€ë¹„ 2ë°°)
            # ì˜ë¯¸: ê°€ì§œ ëŒíŒŒë¥¼ ê±¸ëŸ¬ë‚´ëŠ” ì„¸ë ¥ì˜ ì…ì„± ì¦ê±°
            is_volume = row['Volume'] >= row['VMA5'] * 2.0

            # 6. [ì•ˆì „] ì ì • ì´ê²©ë„ (100~106%)
            # ì˜ë¯¸: ì´ë¯¸ ë„ˆë¬´ ë‚ ì•„ê°„ ì¢…ëª©(ì¶”ê²©ë§¤ìˆ˜)ì€ ê±°ë¥´ëŠ” ì•ˆì „ì¥ì¹˜
            is_safe = 100.0 <= row['Disparity'] <= 106.0

            # 7. [ìˆ˜ê¸‰] OBV ìš°ìƒí–¥ ìœ ì§€
            # ì˜ë¯¸: ì£¼ê°€ëŠ” í”ë“¤ì–´ë„ ëˆ(ë§¤ì§‘ì„¸)ì€ ë¹ ì ¸ë‚˜ê°€ì§€ ì•ŠëŠ” ìƒíƒœ
            is_obv = row['OBV_Slope'] > 0

            # ğŸ† [ìµœì¢… íŒì •] 7ê°€ì§€ ì¤‘ 5ê°€ì§€ ì´ìƒ ë§Œì¡± ì‹œ 'ì •ì˜ˆ', 7ê°€ì§€ ëª¨ë‘ ë§Œì¡± ì‹œ 'LEGEND'
            conditions = [is_yeok, is_mae, is_gong, is_pa, is_volume, is_safe, is_obv]
            match_count = sum(conditions)
            
            # ğŸ’¡ ë§¤ì§‘ 5ê°€ì§€ ì¡°ê±´ ì²´í¬
            acc_1_obv_rising = (row['OBV'] > prev_5['OBV']) and (row['OBV'] > prev_10['OBV'])
            acc_2_box_range = row['Box_Range'] <= 1.15
            acc_3_macd_golden = row['MACD'] > row['MACD_Signal']
            acc_4_rsi_healthy = 40 <= row['RSI'] <= 70
            acc_5_sto_golden = row['Sto_K'] > row['Sto_D']
    
            # ğŸ’¡ [ì‹ ê·œ] ì¡°ìš©í•œ ë§¤ì§‘ íŒ¨í„´ (ë‹¹ì‹ ì´ ë§í•œ ì´ìƒì  ì¡°ê±´!)
            silent_1_atr_low = row['ATR'] < row['ATR_MA20']  # ATRì´ 20ì¼ í‰ê·  ì•„ë˜
            silent_2_mfi_strong = row['MFI'] > 50  # MFI 50 ì´ìƒ
            silent_3_mfi_rising = row['MFI'] > row['MFI_Prev5']  # MFI ìƒìŠ¹ ì¤‘
            silent_4_obv_rising = row['OBV'] > prev_5['OBV']  # OBV ìƒìŠ¹ ì¤‘
            
            # ğŸ’¡ ì¡°ìš©í•œ ë§¤ì§‘ ì™„ì„± ì¡°ê±´ (4ê°œ ëª¨ë‘ ì¶©ì¡±)
            is_silent_accumulation = (silent_1_atr_low and silent_2_mfi_strong and 
                                     silent_3_mfi_rising and silent_4_obv_rising)

            # 3. ì ìˆ˜ ì‚°ì¶œ ë° íƒœê·¸ ë¶€ì—¬
            s_score = 100
            tags = []
            
            # ê¸°ì¡´ ì‹œê·¸ë„ë“¤
            if is_diamond:
                s_score += 150
                tags.append("ğŸ’ë‹¤ì´ì•„ëª¬ë“œ")
                if t_pct < 10:
                    s_score += 50
                    tags.append("ğŸ”¥í­ë°œì§ì „")
            elif is_cloud_brk:
                s_score += 40
                tags.append("â˜ï¸êµ¬ë¦„ëŒíŒŒ")

            if is_super_squeeze: 
                s_score += 40
                tags.append("ğŸ”‹ì´ˆê°•ë ¥ì‘ì¶•")
                
            if is_vol_power: 
                s_score += 30
                tags.append("âš¡ê±°ë˜í­ë°œ")
            
            # ğŸ’¡ ë§¤ì§‘ ì‹œê·¸ë„ ì²´í¬
            acc_count = sum([acc_1_obv_rising, acc_2_box_range, acc_3_macd_golden,
                           acc_4_rsi_healthy, acc_5_sto_golden])
            
            if acc_count >= 4:
                s_score += 60
                tags.append("ğŸ‹ì„¸ë ¥ë§¤ì§‘")
            elif acc_count >= 3:
                s_score += 30
                tags.append("ğŸ‹ë§¤ì§‘ì§•í›„")
                
            if acc_1_obv_rising:
                tags.append("ğŸ“ŠOBVìƒìŠ¹")

            # ğŸ’¡ [ì‹ ê·œ] ì¡°ìš©í•œ ë§¤ì§‘ (ìµœê³  ì ìˆ˜!)
            if is_silent_accumulation:
                s_score += 80
                tags.append("ğŸ¤«ì¡°ìš©í•œë§¤ì§‘ğŸ’°")

            # ì„¸ë¶€ ì¡°ê±´ íƒœê·¸
            if silent_1_atr_low:
                tags.append("ğŸ”‡ATRìˆ˜ì¶•")
            if silent_2_mfi_strong and silent_3_mfi_rising:
                tags.append("ğŸ’°MFIê°•ì„¸")

            # RSI ì •ë³´
            rsi_val = row['RSI']
            if rsi_val >= 80:
                tags.append("ğŸ”¥RSIê°•ì„¸")
                s_score += 10
            elif rsi_val >= 70:
                tags.append("ğŸ“ˆRSIìƒìŠ¹")
            elif rsi_val >= 50:
                tags.append("âœ…RSIì¤‘ë¦½ìƒ")
            elif rsi_val >= 30:
                tags.append("ğŸ“‰RSIí•˜ë½")
            else:
                tags.append("â„ï¸RSIì•½ì„¸")

            # ê¸°ì¡´ ê°ì  ë¡œì§
            if t_pct > 40:
                s_score -= 25
                tags.append("âš ï¸ìœ—ê¼¬ë¦¬")

            # ê¸°ìƒë„ ê°ì 
            storm_count = sum([1 for m in ['ixic', 'sp500'] if row[f'{m}_close'] <= row[f'{m}_ma5']])
            s_score -= (storm_count * 20)
            s_score -= max(0, int((row['Disparity']-108)*5)) 
            
            #print(f"ğŸ•µï¸ [ë¶„ì„ ì¤‘] {name}: {conviction}ì  | ì„œì‚¬: {narrative}")

            # 4. ğŸ’¡ ìˆ˜ìµë¥  ê²€ì¦ ë°ì´í„° ìƒì„± (ìµœê³ /ìµœì € ì¶”ê°€)
            h_df = df.iloc[raw_idx+1:]
            
            if not h_df.empty:
                max_r = ((h_df['High'].max() - close_p) / close_p) * 100
                min_r = ((h_df['Low'].min() - close_p) / close_p) * 100
                
                # ğŸ’¡ ì˜¤ëŠ˜ì´ë©´ í˜„ì¬ê°€ = ì˜¤ëŠ˜ ì¢…ê°€, ì•„ë‹ˆë©´ í•´ë‹¹ ì‹œì ì˜ ë§ˆì§€ë§‰ ì¢…ê°€
                is_today = (len(h_df) == 0)  # ë³´ìœ ì¼ 0ì´ë©´ ì˜¤ëŠ˜
                current_price = today_price if not is_today else close_p
            else:
                max_r = 0
                min_r = 0
                current_price = close_p

            hits.append({
                'ë‚ ì§œ': curr_idx.strftime('%Y-%m-%d'),
                'ğŸ‘‘ë“±ê¸‰': grade,              # ğŸ‘ˆ ì„œì‚¬ ì—”ì§„ ê²°ê³¼ë¬¼ 1
                'ğŸ“œì„œì‚¬íˆìŠ¤í† ë¦¬': narrative,    # ğŸ‘ˆ ì„œì‚¬ ì—”ì§„ ê²°ê³¼ë¬¼ 2
                'í™•ì‹ ì ìˆ˜': conviction,        # ğŸ‘ˆ ì„œì‚¬ ì—”ì§„ ê²°ê³¼ë¬¼ 3
                'ğŸ¯ëª©í‘œíƒ€ì ': int(target),      # ğŸ‘ˆ ì„œì‚¬ ê¸°ë°˜ íƒ€ì 
                'ğŸš¨ì†ì ˆê°€': int(stop),         # ğŸ‘ˆ ì„œì‚¬ ê¸°ë°˜ ì†ì ˆê°€
                'ê¸°ìƒ': "â˜€ï¸" * (2-storm_count) + "ğŸŒªï¸" * storm_count,
                'ì•ˆì „ì ìˆ˜': int(max(0, s_score + whale_score)),
                'ëŒ€ì¹­ë¹„ìœ¨': dante_data['ratio'],
                'ë§¤ì§‘ë´‰': dante_data['mae_jip'],
                'ì„¹í„°': sector,
                'ì¢…ëª©': name,
                'ë§¤ì…ê°€': int(close_p),
                'í˜„ì¬ê°€': int(current_price),
                'ê¼¬ë¦¬%': t_pct,
                'ì´ê²©': int(row['Disparity']),
                'BB40': f"{row['BB40_Width']:.1f}",
                'MAìˆ˜ë ´': f"{row['MA_Convergence']:.1f}",
                'ë§¤ì§‘': f"{acc_count}/5",
                'ìµœê³ ìˆ˜ìµë¥ %': f"{max_r:+.1f}%",
                'ìµœì €ìˆ˜ìµë¥ %': f"{min_r:+.1f}%",
                'ìµœê³ ìˆ˜ìµë¥ _raw': max_r,
                'ìµœì €ìˆ˜ìµë¥ _raw': min_r,
                'êµ¬ë¶„': " ".join(tags),
                'ë³´ìœ ì¼': len(h_df)
            })
        return hits
    except Exception as e:
        print(f"ğŸš¨ [ë³¸ì§„] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        print(f"âœ… [ë³¸ì§„] ì˜¤ë¥˜!")
        return []

# ---------------------------------------------------------
# ğŸ’¾ [ì—‘ì…€ ì €ì¥] ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª© ì €ì¥
# ---------------------------------------------------------
def save_today_recommendations(df_today, recommendation_info):
    """ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª©ì„ ì—‘ì…€ë¡œ ì €ì¥"""
    try:
        filename = f"ì¶”ì²œì¢…ëª©_{TODAY_STR}.xlsx"
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # ì‹œíŠ¸1: ì˜¤ëŠ˜ì˜ ì¶”ì²œ ì¢…ëª©
            df_today.to_excel(writer, sheet_name='ì˜¤ëŠ˜ì˜_ì¶”ì²œ', index=False)
            
            # ì‹œíŠ¸2: ì¶”ì²œ ì •ë³´
            if recommendation_info:
                rec_df = pd.DataFrame([recommendation_info])
                rec_df.to_excel(writer, sheet_name='ì¶”ì²œ_íŒ¨í„´_ì •ë³´', index=False)
        
        print(f"\nğŸ’¾ ì—‘ì…€ ì €ì¥ ì™„ë£Œ: {filename}")
        return filename
    except Exception as e:
        print(f"\nâŒ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

# =================================================
# ğŸš€ [ì‹¤í–‰] ë©”ì¸ ì»¨íŠ¸ë¡¤ëŸ¬ (ìˆ˜ì • ë²„ì „)
# =================================================
if __name__ == "__main__":
    print(f"ğŸ“¡ [Ver 36.7 êµ¬ê¸€ì‹œíŠ¸ ê°•í™”] {TODAY_STR} ì „ìˆ  ì‚¬ë ¹ë¶€ í†µí•© ê°€ë™...")
    commander_cap_map = get_commander_market_cap()
    # ğŸ’¡ 1. ì „ìŸ ì‹œì‘ ì „ 'ëŒ€ì¥ì£¼ ì§€ë„'ì™€ 'ê·¸ë“¤ì˜ ìƒíƒœ'ë¥¼ ë”± í•œ ë²ˆë§Œ ìƒì„±
    # leader_map: {ì„¹í„°: ì½”ë“œ}, leader_status: {ì„¹í„°: ê°•ì„¸/ì¹¨ì²´}
    global_env, leader_env = get_global_and_leader_status()

    # 2. ì „ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ë° ëª…ì°° ê°•ì œ í†µì¼
    try:
        df_krx = fdr.StockListing('KRX')
        
        # ğŸ’¡ [í•µì‹¬] ì²« ë²ˆì§¸ ì—´ì€ 'Code', ë‘ ë²ˆì§¸ ì—´ì€ 'Name'ìœ¼ë¡œ ê°•ì œ ê°œëª…
        # KRX ë°ì´í„° êµ¬ì¡°ìƒ ë³´í†µ 0ë²ˆì´ ì½”ë“œ, 1ë²ˆì´ ì¢…ëª©ëª…ì…ë‹ˆë‹¤.
        #df_krx.columns.values[0] = target_stocks['Code']
        #df_krx.columns.values[1] = target_stocks['Name']
        
        # ì„¹í„° ì»¬ëŸ¼ë„ ìˆìœ¼ë©´ 'Sector'ë¡œ í†µì¼
        s_col = next((c for c in ['Sector', 'Industry', 'ì—…ì¢…'] if c in df_krx.columns), None)
        if s_col:
            df_krx = df_krx.rename(columns={s_col: 'Sector'})
            sector_master_map = df_krx.set_index('Code')['Sector'].to_dict()
        else:
            sector_master_map = {k: 'ì¼ë°˜' for k in df_krx['Code']}
            
        print(f"âœ… [ë³¸ì§„] ëª…ì°° í†µì¼ ì™„ë£Œ: {len(df_krx)}ê°œ ì¢…ëª© ë¡œë“œ")

    except Exception as e:
        print(f"ğŸš¨ [ë³¸ì§„] ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        sector_master_map = {}
        # ì—¬ê¸°ì„œ ì£½ì§€ ì•Šê²Œ ë¹ˆ ë°ì´í„°í”„ë ˆì„ì´ë¼ë„ ìƒì„±
        df_krx = pd.DataFrame(columns=['Code', 'Name', 'Sector'])

    target_stocks = df_krx.sort_values(by='Amount', ascending=False).head(TOP_N)
    
    # 1. ë§¤í¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
    m_ndx = get_safe_macro('^IXIC', 'ë‚˜ìŠ¤ë‹¥')
    m_sp5 = get_safe_macro('^GSPC', 'S&P500')
    m_vix = get_safe_macro('^VIX', 'VIXê³µí¬')
    m_fx  = get_safe_macro('USD/KRW', 'ë‹¬ëŸ¬í™˜ìœ¨')
    
    kospi_supply = get_index_investor_data('KOSPI')
    macro_status = {'nasdaq': m_ndx, 'sp500': m_sp5, 'vix': m_vix, 'fx': m_fx, 'kospi': kospi_supply}

    print("\n" + "ğŸŒ " * 5 + "[ ê¸€ë¡œë²Œ ì‚¬ë ¹ë¶€ í†µí•© ê´€ì œ ì„¼í„° ]" + " ğŸŒ" * 5)
    print(f"ğŸ‡ºğŸ‡¸ {m_ndx['text']} | {m_sp5['text']} | âš ï¸ {m_vix['text']}")
    print(f"ğŸ’µ {m_fx['text']} | ğŸ‡°ğŸ‡· KOSPI ìˆ˜ê¸‰: {kospi_supply}")
    print("=" * 115)
    
    weather_data = prepare_historical_weather()
    
    # 2. ê¸€ë¡œë²Œ/ëŒ€ì¥ì£¼ ìƒíƒœ ìŠ¤ìº”
    g_status, l_sync = get_global_and_leader_status()
  
    # 3. ì „ìˆ  ìŠ¤ìº” (ë©€í‹°ìŠ¤ë ˆë”©)
    all_hits = []
    print(f"ğŸ” ì´ {len(target_stocks)}ê°œ ì¢…ëª© ğŸ’ë‹¤ì´ì•„ëª¬ë“œ & ğŸ¯ì—­ë§¤ê³µíŒŒ ë ˆì´ë” ê°€ë™...")
    with ThreadPoolExecutor(max_workers=15) as executor:
        results = list(executor.map(
            lambda p: analyze_final(p[0], p[1], weather_data, global_env, leader_env, sector_master_map), 
            zip(target_stocks['Code'], target_stocks['Name'])
        ))
        for r in results:
            if r:
                # ğŸ’¡ [ì‹ ê·œ] í¬ì°©ëœ ì¢…ëª©ì— ì¦‰ì‹œ ì²´ê¸‰(Tier) ë° ì‹œì´ ë°ì´í„° ì£¼ì…
                for hit in r:
                    # hit['ì¢…ëª©ì½”ë“œ']ê°€ ìˆë‹¤ê³  ê°€ì •, ì—†ìœ¼ë©´ tickerë¥¼ ì°¾ì•„ì•¼ í•¨
                    name = hit['ì¢…ëª©']
                    ticker_code = hit.get('ì½”ë“œ')
                    all_hits.append(hit)

    if all_hits:
        df_total = pd.DataFrame(all_hits)

        # í†µê³„ ê³„ì‚° (ìƒìœ„ 5ê°œ ì¶”ì²œ ì •ë³´ í¬í•¨)
        stats_df, top_recommendations = calculate_strategy_stats(all_hits)

        # 4. ê²°ê³¼ ë¶„ë¥˜
        today = df_total[df_total['ë³´ìœ ì¼'] == 0].sort_values(by='í™•ì‹ ì ìˆ˜', ascending=False)
        desired_cols = ['ë‚ ì§œ',
                'ğŸ‘‘ë“±ê¸‰',
                'ì¢…ëª©',
                'ëŒ€ì¹­ë¹„ìœ¨',
                'ë§¤ì§‘ë´‰',
                'ğŸ¯ëª©í‘œíƒ€ì ',
                'ğŸš¨ì†ì ˆê°€',
                'ë§¤ì…ê°€',
                'í˜„ì¬ê°€',
                'ìµœê³ ìˆ˜ìµë¥ %',
                'ìµœì €ìˆ˜ìµë¥ %',
                'ê¸°ìƒ',
                'ë§¤ì§‘',
                'ì´ê²©',
                'ê¼¬ë¦¬%',
                'BB40',
                'MAìˆ˜ë ´',
                'ğŸ“œì„œì‚¬íˆìŠ¤í† ë¦¬',
                'êµ¬ë¶„',
                'í™•ì‹ ì ìˆ˜',
                'ì•ˆì „ì ìˆ˜',
                'ì„¹í„°',
                'ìµœê³ ìˆ˜ìµë¥ _raw',
                'ìµœì €ìˆ˜ìµë¥ _raw',
                'ë³´ìœ ì¼']
        display_cols = [c for c in desired_cols if c in today.columns]

        if not today.empty:
            print(today[display_cols].head(50))
        # 5. êµ¬ê¸€ ì‹œíŠ¸ ì „ì†¡
        try:
            update_commander_dashboard(
                df_total[display_cols].sort_values(by='í™•ì‹ ì ìˆ˜', ascending=False),
                macro_status, 
                "ì‚¬ë ¹ë¶€_í†µí•©_ìƒí™©íŒ", 
                stats_df if not stats_df.empty else None,
                today[display_cols],  # ì˜¤ëŠ˜ì˜_ì¶”ì²œì¢…ëª© íƒ­: ì˜¤ëŠ˜ë§Œ (ëª¨ë“  íŒ¨í„´ í†µí•©)
                None
            )
            print("\nâœ… êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì„±ê³µ!")
            print("   ğŸ“‹ ë©”ì¸ ì‹œíŠ¸")
            print("   ğŸ¯ ì˜¤ëŠ˜ì˜_ì¶”ì²œì¢…ëª© íƒ­: ì˜¤ëŠ˜ ì‹ í˜¸ë§Œ (TOP 50, ëª¨ë“  íŒ¨í„´ í†µí•©)")
        except Exception as e:
            print(f"\nâŒ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    else:
        print("\nâš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
