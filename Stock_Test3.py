# ------------------------------------------------------------------
# ğŸ’ [Ultimate Masterpiece] ì „ì²œí›„ AI ì „ëµ ì‚¬ë ¹ë¶€ (Ver 36.7 ì—‘ì…€ì €ì¥+ì¶”ì²œì‹œìŠ¤í…œ)
# ------------------------------------------------------------------
import FinanceDataReader as fdr
import os, re, time, pytz
from pykrx import stock
import pandas as pd
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
import warnings
import requests
from bs4 import BeautifulSoup
from DNA_Analyzer import analyze_dna_sequences, find_winning_pattern
from tactics_engine import get_global_and_leader_status, analyze_all_narratives

from pykrx import stock
import pandas as pd
from datetime import datetime

# ğŸ‘‡ êµ¬ê¸€ ì‹œíŠ¸ ë§¤ë‹ˆì € ì—°ê²° (íŒŒì¼ëª… í™•ì¸ í•„ìˆ˜)
try:
    from google_sheet_managerEx import update_commander_dashboard
except ImportError:
    def update_commander_dashboard(*args, **kwargs): print("âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ëª¨ë“ˆ ì—°ê²° ì‹¤íŒ¨")

warnings.filterwarnings('ignore')

# =================================================
# âš™ï¸ [1. ì„¤ì • ë° ê¸€ë¡œë²Œ ë³€ìˆ˜]
# =================================================
SCAN_DAYS = 20     # ìµœê·¼ 30ì¼ ë‚´ íƒ€ì  ì „ìˆ˜ ì¡°ì‚¬
TOP_N = 2500        # ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª© ìˆ˜ (í•„ìš”ì‹œ 2500ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥)
KST = pytz.timezone('Asia/Seoul')
NOW = datetime.now(KST)
TODAY_STR = NOW.strftime('%Y-%m-%d')
START_DATE = (datetime.now() - timedelta(days=600)).strftime('%Y-%m-%d')
END_DATE_STR = datetime.now().strftime('%Y%m%d')

print(f"ğŸ“¡ [Ver 36.7 ì—‘ì…€ì €ì¥+ì¶”ì²œ] ì‚¬ë ¹ë¶€ ë¬´ê²°ì„± í†µí•© ê°€ë™... ğŸ’ë‹¤ì´ì•„ëª¬ë“œ & ğŸ“Šë³µí•©í†µê³„ ì—”ì§„ íƒ‘ì¬")

def get_dynamic_sector_leaders():
    """
    ì˜¤ëŠ˜ ì•„ì¹¨ ì‹œê°€ì´ì•¡ì„ ê¸°ì¤€ìœ¼ë¡œ ê° ì„¹í„°ë³„ ì‚¬ë ¹ê´€(ëŒ€ì¥ì£¼)ì„ ìë™ ì„ ì¶œí•©ë‹ˆë‹¤.
    """
    print("ğŸ“¡ [Leader-Scanner] ì˜¤ëŠ˜ì˜ ì„¹í„°ë³„ ëŒ€ì¥ì£¼ ì„ ì¶œ ì¤‘...")
    
    # 1. KRX ì „ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë° ì—…ì¢… ì •ë³´ (FinanceDataReader)
    df_krx = fdr.StockListing('KRX') 
    
    # 2. ì „ ì¢…ëª© ì‹œê°€ì´ì•¡ ì •ë³´ (Pykrx)
    now = datetime.now().strftime("%Y%m%d")
    df_cap = stock.get_market_cap(now, market="ALL")[['ì‹œê°€ì´ì•¡']]
    
    # 3. ë°ì´í„° ë³‘í•© (ì¢…ëª©ì½”ë“œ ê¸°ì¤€)
    # df_krxì˜ Symbolì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•˜ì—¬ ì‹œê°€ì´ì•¡ê³¼ í•©ì¹©ë‹ˆë‹¤.
    df_master = df_krx.set_index('Symbol').join(df_cap)
    
    # 4. ì„¹í„°ë³„ ì‹œê°€ì´ì•¡ 1ìœ„ ì¢…ëª© ì¶”ì¶œ
    # Sectorê°€ ì—†ëŠ” ì¢…ëª©(ETF ë“±)ì€ ì œì™¸í•˜ê³  ê·¸ë£¹í™”
    df_valid = df_master.dropna(subset=['Sector'])
    
    # ê° ì„¹í„°ì—ì„œ ì‹œê°€ì´ì•¡(ì‹œê°€ì´ì•¡ ì»¬ëŸ¼)ì´ ê°€ì¥ í° í–‰ì˜ ì¸ë±ìŠ¤(ì¢…ëª©ì½”ë“œ)ë¥¼ ê°€ì ¸ì˜´
    leader_indices = df_valid.groupby('Sector')['ì‹œê°€ì´ì•¡'].idxmax()
    
    # {ì„¹í„°ëª…: ì¢…ëª©ì½”ë“œ} ë§µ ìƒì„±
    sector_leader_map = leader_indices.to_dict()
    
    # ì—­ìœ¼ë¡œ {ì¢…ëª©ì½”ë“œ: ì„¹í„°ëª…} ë§µë„ ìƒì„± (ë¶„ì„ ì‹œ ëŒ€ì¥ì£¼ ì—¬ë¶€ í™•ì¸ìš©)
    leader_ticker_map = {v: k for k, v in sector_leader_map.items()}
    
    print(f"âœ… ì´ {len(sector_leader_map)}ê°œ ì„¹í„°ì˜ ì‚¬ë ¹ê´€ ì„ ì¶œ ì™„ë£Œ.")
    return sector_leader_map, leader_ticker_map

def get_stock_sector(ticker, sector_map):
    """
    ê¸°ì¡´ì— ìˆ˜ì§‘ëœ ì„¹í„° ë§ˆìŠ¤í„° ë§µì—ì„œ ì¢…ëª©ì˜ ì—…ì¢…ì„ íŒë…í•©ë‹ˆë‹¤.
    """
    # 1. ë§ˆìŠ¤í„° ë§µì—ì„œ í•´ë‹¹ ì¢…ëª©ì˜ ì—…ì¢…ëª… ì¶”ì¶œ
    raw_sector = sector_map.get(ticker, "ì¼ë°˜")
    
    # 2. í‚¤ì›Œë“œ ë§¤ì¹­ì„ í†µí•œ ì„¹í„° ì •ê·œí™” (ëŒ€ì¥ì£¼ ë™ê¸°í™”ìš©)
    if any(k in raw_sector for k in ['ë°˜ë„ì²´', 'ITë¶€í’ˆ', 'ì¥ë¹„']): 
        return "ë°˜ë„ì²´"
    if any(k in raw_sector for k in ['ì œì•½', 'ë°”ì´ì˜¤', 'ì˜ë£Œê¸°ê¸°', 'ìƒë¬¼']): 
        return "ë°”ì´ì˜¤"
    if any(k in raw_sector for k in ['ì „ê¸°ì°¨', 'ë°°í„°ë¦¬', 'ì—ë„ˆì§€', 'ì¶•ì „ì§€']): 
        return "2ì°¨ì „ì§€"
    
    return "ì¼ë°˜"

def get_commander_market_cap():
    """
    ì´ë¦„ê³¼ ì½”ë“œ, ì–´ë–¤ ê²ƒìœ¼ë¡œë„ ì²´ê¸‰ì„ ì¦‰ì‹œ íŒë…í•  ìˆ˜ ìˆëŠ” ë§ˆìŠ¤í„° ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("ğŸ“¡ [Cap-Scanner] ì „ ì¢…ëª© ë§ˆìŠ¤í„° ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    try:
        now = datetime.now().strftime("%Y%m%d")
        # 1. ì‹œê°€ì´ì•¡ ë°ì´í„° (ì¸ë±ìŠ¤ê°€ ì¢…ëª©ì½”ë“œ)
        df_cap = stock.get_market_cap(now, market="ALL")
        
        # 2. ì¢…ëª©ëª… ë°ì´í„° (ì¢…ëª©ì½”ë“œ, ì¢…ëª©ëª… ë§¤í•‘)
        df_desc = stock.get_market_net_purchases_of_equities_by_ticker(now, now, "ALL") # ì´ë¦„ ê°€ì ¸ì˜¤ê¸°ìš© íŒ
        # ë” í™•ì‹¤í•œ ì´ë¦„-ì½”ë“œ ë§¤í•‘
        tickers = stock.get_market_ticker_list(now, market="ALL")
        names = [stock.get_market_ticker_name(t) for t in tickers]
        df_name = pd.DataFrame({'Code': tickers, 'Name': names}).set_index('Code')

        # 3. ë°ì´í„° ë³‘í•©
        master_df = df_cap.join(df_name)
        
        # ğŸ’¡ [í•µì‹¬] ë‘ ê°€ì§€ íƒ€ì…ì˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        code_to_cap = master_df['ì‹œê°€ì´ì•¡'].to_dict()
        name_to_cap = master_df.set_index('Name')['ì‹œê°€ì´ì•¡'].to_dict()

        print(f"âœ… [Cap-Scanner] ë§ˆìŠ¤í„° ë°ì´í„° {len(code_to_cap)}ê±´ ë¡œë“œ ì™„ë£Œ.")
        return {"code": code_to_cap, "name": name_to_cap}
    except Exception as e:
        print(f"âŒ [Cap-Scanner] ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return {"code": {}, "name": {}}

def assign_tier(name, code, master_map):
    """
    ì½”ë“œ ìš°ì„ , ì´ë¦„ ì°¨ì„ ìœ¼ë¡œ ì²´ê¸‰ì„ ê²°ì •í•©ë‹ˆë‹¤.
    """
    # 1. ì½”ë“œë¡œ ì¡°íšŒ ì‹œë„
    cap = master_map['code'].get(code, 0)
    
    # 2. ì½”ë“œë¡œ ì‹¤íŒ¨ ì‹œ ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ ì‹œë„
    if cap == 0:
        cap = master_map['name'].get(name, 0)
    
    # 3. ì²´ê¸‰ ê²°ì •
    if cap >= 1_000_000_000_000: return "ğŸ‘‘HEAVY", cap
    if cap >= 200_000_000_000: return "âš”ï¸MIDDLE", cap
    if cap > 0: return "ğŸš€LIGHT", cap
    
    return "â“ë¯¸í™•ì¸", 0

# ---------------------------------------------------------
# ğŸŒ [ë§¤í¬ë¡œ ì—”ì§„] ê¸€ë¡œë²Œ ì§€ìˆ˜ ë° ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘
# ---------------------------------------------------------
def get_safe_macro(symbol, name):
    try:
        df = fdr.DataReader(symbol, start=(datetime.now() - timedelta(days=15)).strftime('%Y-%m-%d'))
        curr, prev = df.iloc[-1]['Close'], df.iloc[-2]['Close']
        ma5 = df['Close'].tail(5).mean()
        chg = ((curr - prev) / prev) * 100
        status = "â˜€ï¸ë§‘ìŒ" if curr > ma5 else "ğŸŒªï¸í­í’ìš°"
        if "VIX" in name: status = "â˜€ï¸ì•ˆì •" if curr < ma5 else "ğŸŒªï¸ìœ„í—˜"
        return {"val": curr, "chg": chg, "status": status, "text": f"{name}: {curr:,.2f}({chg:+.2f}%) {status}"}
    except: return {"status": "â˜ï¸ë¶ˆëª…", "text": f"{name}: ì—°ê²°ì‹¤íŒ¨"}

def get_index_investor_data(market_name):
    try:
        df = stock.get_market_net_purchases_of_equities(END_DATE_STR, END_DATE_STR, market_name)
        if df.empty:
            prev_day = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
            df = stock.get_market_net_purchases_of_equities(prev_day, prev_day, market_name)
        total = df.sum()
        return f"ê°œì¸ {total['ê°œì¸']:+,.0f} | ì™¸ì¸ {total['ì™¸êµ­ì¸']:+,.0f} | ê¸°ê´€ {total['ê¸°ê´€í•©ê³„']:+,.0f}"
    except: return "ë°ì´í„° ìˆ˜ì‹  ì¤‘..."

def prepare_historical_weather():
    """ì—­ì‚¬ì  ê¸°ìƒë„ë¥¼ ì‘ì„±í•˜ì—¬ analyze_finalì— ë³´ê¸‰í•©ë‹ˆë‹¤."""
    start_point = (datetime.now() - timedelta(days=600)).strftime('%Y-%m-%d')
    ndx = fdr.DataReader('^IXIC', start=start_point)[['Close']]
    sp5 = fdr.DataReader('^GSPC', start=start_point)[['Close']]
    ndx['ixic_ma5'] = ndx['Close'].rolling(5).mean()
    sp5['sp500_ma5'] = sp5['Close'].rolling(5).mean()
    weather_df = pd.concat([
        ndx.rename(columns={'Close': 'ixic_close'}),
        sp5.rename(columns={'Close': 'sp500_close'})
    ], axis=1).fillna(method='ffill')
    return weather_df

# ---------------------------------------------------------
# ğŸ“Š [ì „ìˆ  í†µê³„] ë³µí•© ì „ìˆ  í†µê³„ ì—”ì§„ (ìƒìœ„ 5ê°œ ì¶”ì²œ)
# ---------------------------------------------------------
def calculate_strategy_stats(all_hits):
    past_hits = [h for h in all_hits if h['ë³´ìœ ì¼'] > 0]
    if not past_hits: return pd.DataFrame(), None
    
    stats = {}
    for h in past_hits:
        raw_tags = h['êµ¬ë¶„'].split()
        if not raw_tags: continue
        
        # ê°œë³„ íƒœê·¸ ë° ë³µí•© íƒœê·¸ ìƒì„±
        combos = []
        for tag in raw_tags:
            combos.append(tag)
        
        # 2ê°œ ì¡°í•©
        if len(raw_tags) >= 2:
            sorted_tags = sorted(raw_tags)
            for i in range(len(sorted_tags)):
                for j in range(i+1, len(sorted_tags)):
                    combos.append(f"{sorted_tags[i]} + {sorted_tags[j]}")
        
        # ì „ì²´ ì¡°í•©
        if len(raw_tags) > 1:
            combos.append(" + ".join(sorted(raw_tags)))
        
        for strategy in set(combos):
            if strategy not in stats: 
                stats[strategy] = {'total': 0, 'hits': 0, 'yields': [], 'min_yields': []}
            stats[strategy]['total'] += 1
            if h['ìµœê³ ìˆ˜ìµë¥ _raw'] >= 3.5: stats[strategy]['hits'] += 1
            stats[strategy]['yields'].append(h['ìµœê³ ìˆ˜ìµë¥ _raw'])
            stats[strategy]['min_yields'].append(h['ìµœì €ìˆ˜ìµë¥ _raw'])

    report_data = []
    for strategy, data in stats.items():
        avg_max_yield = sum(data['yields']) / data['total']
        avg_min_yield = sum(data['min_yields']) / data['total']
        hit_rate = (data['hits'] / data['total']) * 100
        
        # ê¸°ëŒ€ê°’ ê³„ì‚° (í™•ë¥  * ìˆ˜ìµë¥ )
        expected_value = (hit_rate / 100) * avg_max_yield
        
        report_data.append({
            'ì „ëµëª…': strategy, 
            'í¬ì°©ê±´ìˆ˜': data['total'], 
            'íƒ€ìœ¨(ìŠ¹ë¥ )': round(hit_rate, 1), 
            'í‰ê· ìµœê³ ìˆ˜ìµ': round(avg_max_yield, 1),
            'í‰ê· ìµœì €ìˆ˜ìµ': round(avg_min_yield, 1),
            'ê¸°ëŒ€ê°’': round(expected_value, 2)
        })
    
    df_stats = pd.DataFrame(report_data).sort_values(
        by=['ê¸°ëŒ€ê°’', 'í‰ê· ìµœê³ ìˆ˜ìµ', 'íƒ€ìœ¨(ìŠ¹ë¥ )'], 
        ascending=False
    )
    
    # ğŸ’¡ ìƒìœ„ 3~5ê°œ íŒ¨í„´ ì¶”ì²œ
    top_recommendations = []
    if len(df_stats) > 0:
        # ìµœì†Œ 5ê±´ ì´ìƒ ë°ì´í„° ìˆëŠ” íŒ¨í„´ ìš°ì„ 
        reliable_patterns = df_stats[df_stats['í¬ì°©ê±´ìˆ˜'] >= 5]
        
        if len(reliable_patterns) >= 3:
            # ì‹ ë¢°ë„ ë†’ì€ íŒ¨í„´ ì¤‘ ìƒìœ„ 5ê°œ
            top_5 = reliable_patterns.head(5)
            for idx, row in top_5.iterrows():
                top_recommendations.append({
                    'ìˆœìœ„': len(top_recommendations) + 1,
                    'íŒ¨í„´': row['ì „ëµëª…'],
                    'íƒ€ìœ¨': row['íƒ€ìœ¨(ìŠ¹ë¥ )'],
                    'í‰ê· ìˆ˜ìµ': row['í‰ê· ìµœê³ ìˆ˜ìµ'],
                    'ê¸°ëŒ€ê°’': row['ê¸°ëŒ€ê°’'],
                    'ê±´ìˆ˜': row['í¬ì°©ê±´ìˆ˜'],
                    'ì‹ ë¢°ë„': 'â­â­â­ ë†’ìŒ'
                })
        else:
            # ë°ì´í„° ë¶€ì¡±ì‹œ ì „ì²´ì—ì„œ ìƒìœ„ 5ê°œ
            top_5 = df_stats.head(5)
            for idx, row in top_5.iterrows():
                reliability = 'â­â­â­ ë†’ìŒ' if row['í¬ì°©ê±´ìˆ˜'] >= 5 else 'â­â­ ë³´í†µ' if row['í¬ì°©ê±´ìˆ˜'] >= 3 else 'â­ ì£¼ì˜'
                top_recommendations.append({
                    'ìˆœìœ„': len(top_recommendations) + 1,
                    'íŒ¨í„´': row['ì „ëµëª…'],
                    'íƒ€ìœ¨': row['íƒ€ìœ¨(ìŠ¹ë¥ )'],
                    'í‰ê· ìˆ˜ìµ': row['í‰ê· ìµœê³ ìˆ˜ìµ'],
                    'ê¸°ëŒ€ê°’': row['ê¸°ëŒ€ê°’'],
                    'ê±´ìˆ˜': row['í¬ì°©ê±´ìˆ˜'],
                    'ì‹ ë¢°ë„': reliability
                })
    
    return df_stats, top_recommendations

# ---------------------------------------------------------
# ğŸ“ˆ [ë°ì´í„°] ë§ˆìŠ¤í„° ì§€í‘œ ì—”ì§„ (Ver 36.7)
# ---------------------------------------------------------
def get_indicators(df):
    df = df.copy()
    count = len(df)
    
    # ë‹¨í…Œ ì¥ê¸°ì„  í¬í•¨ ì´í‰ì„ 
    for n in [5, 20, 40, 60, 112, 224]:
        df[f'MA{n}'] = df['Close'].rolling(window=min(count, n)).mean()
        df[f'VMA{n}'] = df['Volume'].rolling(window=min(count, n)).mean()
    
    # 20/40ì¼ BB Width (ì´ì¤‘ ì‘ì¶•)
    std20 = df['Close'].rolling(20).std()
    df['BB_Upper'] = df['MA20'] + (std20 * 2)
    df['BB20_Width'] = (std20 * 4) / df['MA20'] * 100
    std40 = df['Close'].rolling(40).std()
    df['BB40_Upper'] = df['MA40'] + (std40 * 2)
    df['BB40_Lower'] = df['MA40'] - (std40 * 2)
    df['BB40_Width'] = (std40 * 4) / df['MA40'] * 100
    
    # ì´í‰ì„  ìˆ˜ë ´ë„ ê³„ì‚°
    df['MA_Convergence'] = abs(df['MA20'] - df['MA60']) / df['MA60'] * 100
    
    # ì¼ëª©ê· í˜•í‘œ
    df['Tenkan_sen'] = (df['High'].rolling(9).max() + df['Low'].rolling(9).min()) / 2
    df['Kijun_sen'] = (df['High'].rolling(26).max() + df['Low'].rolling(26).min()) / 2
    df['Span_A'] = ((df['Tenkan_sen'] + df['Kijun_sen']) / 2).shift(26)
    df['Span_B'] = ((df['High'].rolling(52).max() + df['Low'].rolling(52).min()) / 2).shift(26)
    df['Cloud_Top'] = df[['Span_A', 'Span_B']].max(axis=1)

    # ìŠ¤í† ìºìŠ¤í‹±
    l_min, h_max = df['Low'].rolling(12).min(), df['High'].rolling(12).max()
    df['Sto_K'] = ((df['Close'] - l_min) / (h_max - l_min)) * 100
    df['Sto_D'] = df['Sto_K'].rolling(5).mean()
    df['Sto_SD'] = df['Sto_D'].rolling(5).mean()
    
    # ADX
    high, low, close = df['High'], df['Low'], df['Close']
    tr = pd.concat([high - low, abs(high - close.shift(1)), abs(low - close.shift(1))], axis=1).max(axis=1)
    df['ADX'] = ((abs((high-high.shift(1)).clip(lower=0).rolling(14).sum() - (low.shift(1)-low).clip(lower=0).rolling(14).sum()) / 
                ((high-high.shift(1)).clip(lower=0).rolling(14).sum() + (low.shift(1)-low).clip(lower=0).rolling(14).sum())) * 100).rolling(14).mean()
    
    # MACD
    ema12 = df['Close'].ewm(span=12).mean()
    ema26 = df['Close'].ewm(span=26).mean()
    df['MACD'] = ema12 - ema26
    df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']
    
    # OBV
    df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
    df['OBV_Slope'] = (df['OBV'] - df['OBV'].shift(5)) / df['OBV'].shift(5).abs() * 100
    
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    
    df['Disparity'] = (df['Close'] / df['MA20']) * 100
    df['Box_Range'] = df['High'].rolling(10).max() / df['Low'].rolling(10).min()
    
    return df

# ---------------------------------------------------------
# ğŸ•µï¸â€â™‚ï¸ [ë¶„ì„] ì •ë°€ ë¶„ì„ ì—”ì§„ (Ver 36.7 ìµœì €ìˆ˜ìµë¥  ì¶”ê°€)
# ---------------------------------------------------------
def analyze_final(ticker, name, historical_indices, g_status, l_sync, sector_master_map):
    try:
        df = fdr.DataReader(ticker, start=START_DATE)
        if len(df) < 100: return []
        df = get_indicators(df)
        df = df.join(historical_indices, how='left').fillna(method='ffill')

        # ğŸ•µï¸ ì‹ ê·œ ì¶”ê°€: ì„œì‚¬ ë¶„ì„ê¸° í˜¸ì¶œ
        sector = get_stock_sector(ticker, sector_master_map) # ì„¹í„° íŒë… í•¨ìˆ˜ í•„ìš”
        grade, narrative, target, stop, conviction = analyze_all_narratives(
            df, name, sector, g_status, l_sync
        )
      
        # ğŸ’¡ ì˜¤ëŠ˜ì˜ í˜„ì¬ê°€ ì €ì¥ (ë‚˜ì¤‘ì— ì‚¬ìš©)
        today_price = df.iloc[-1]['Close']
        
        # ìµœì‹  ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘
        try:
            url = f"https://finance.naver.com/item/frgn.naver?code={ticker}"
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=5)
            res.encoding = 'euc-kr'
            supply_df = pd.read_html(res.text)[2].dropna()
            f_qty = int(str(supply_df.iloc[0]['ì™¸êµ­ì¸']).replace('.0','').replace(',',''))
            i_qty = int(str(supply_df.iloc[0]['ê¸°ê´€']).replace('.0','').replace(',',''))
            twin_b = (f_qty > 0 and i_qty > 0)
            whale_score = int(((f_qty + i_qty) * df.iloc[-1]['Close']) / 100000000)
        except:
            f_qty, i_qty, twin_b, whale_score = 0, 0, False, 0

        recent_df = df.tail(SCAN_DAYS)
        hits = []

        for curr_idx, row in recent_df.iterrows():
            raw_idx = df.index.get_loc(curr_idx)
            if raw_idx < 100: continue
            prev = df.iloc[raw_idx-1]
            prev_5 = df.iloc[max(0, raw_idx-5)]
            prev_10 = df.iloc[max(0, raw_idx-10)]
            
            # 1. ê¼¬ë¦¬% ì •ë°€ ê³„ì‚°
            high_p, low_p, close_p, open_p = row['High'], row['Low'], row['Close'], row['Open']
            body_max = max(open_p, close_p)
            t_pct = int((high_p - body_max) / (high_p - low_p) * 100) if high_p != low_p else 0

            # 2. ê¸°ì¡´ í•µì‹¬ ì „ìˆ  ì‹ í˜¸ íŒì •
            is_cloud_brk = prev['Close'] <= prev['Cloud_Top'] and close_p > row['Cloud_Top']
            is_kijun_sup = close_p > row['Kijun_sen'] and prev['Close'] <= prev['Kijun_sen']
            is_diamond = is_cloud_brk and is_kijun_sup
            
            is_super_squeeze = row['BB20_Width'] < 10 and row['BB40_Width'] < 15
            is_yeok_mae_old = close_p > row['MA112'] and prev['Close'] <= row['MA112']
            is_vol_power = row['Volume'] > row['VMA20'] * 2.5

            # --- [ì—­ë§¤ê³µíŒŒ í†µí•© 7ë‹¨ê³„ ë¡œì§] ---
            # 1. [ì—­(é€†)] ì—­ë°°ì—´ ë°”ë‹¥ íƒˆì¶œ (5/20 ê³¨ë“ í¬ë¡œìŠ¤)
            # ì˜ë¯¸: í•˜ë½ì„ ë©ˆì¶”ê³  ë‹¨ê¸° ì¶”ì„¸ë¥¼ ëŒë¦¬ëŠ” ì²« ì‹ í˜¸
            is_yeok = (prev['MA5'] <= prev['MA20']) and (row['MA5'] > row['MA20'])

            # 2. [ë§¤(åŸ‹)] ì—ë„ˆì§€ ì‘ì¶• (ì´í‰ì„  ë°€ì§‘)
            # ì˜ë¯¸: 5, 20, 60ì¼ì„ ì´ 3% ì´ë‚´ë¡œ ëª¨ì—¬ ì—ë„ˆì§€ê°€ ì••ì¶•ëœ ìƒíƒœ
            is_mae = row['MA_Convergence'] <= 3.0

            # 3. [ê³µ(ç©º)] ê³µêµ¬ë¦¬ ëŒíŒŒ (MA112 ëŒíŒŒ) - ì‚¬ë ¹ê´€ë‹˜ì´ ì°¾ì•„ë‚¸ í•µì‹¬!
            # ì˜ë¯¸: 6ê°œì›” ì¥ê¸° ì €í•­ì„ (ê³µêµ¬ë¦¬)ì„ ì¢…ê°€ë¡œ ëš«ì–´ë²„ë¦¬ëŠ” ìˆœê°„
            is_gong = (close_p > row['MA112']) and (prev['Close'] <= row['MA112'])

            # 4. [íŒŒ(ç ´)] íŒŒë™ì˜ ì‹œì‘ (BB40 ìƒë‹¨ ëŒíŒŒ)
            # ì˜ë¯¸: ë³¼ë¦°ì €ë°´ë“œ ìƒë‹¨ì„ ëš«ê³  ë³€ë™ì„±ì´ ìœ„ë¡œ í„°ì§€ëŠ” ì‹œì 
            is_pa = (row['Close'] > row['BB40_Upper']) and (prev['Close'] <= row['BB40_Upper'])

            # 5. [í™”ë ¥] ê±°ë˜ëŸ‰ ë™ë°˜ (VMA5 ëŒ€ë¹„ 2ë°°)
            # ì˜ë¯¸: ê°€ì§œ ëŒíŒŒë¥¼ ê±¸ëŸ¬ë‚´ëŠ” ì„¸ë ¥ì˜ ì…ì„± ì¦ê±°
            is_volume = row['Volume'] >= row['VMA5'] * 2.0

            # 6. [ì•ˆì „] ì ì • ì´ê²©ë„ (100~106%)
            # ì˜ë¯¸: ì´ë¯¸ ë„ˆë¬´ ë‚ ì•„ê°„ ì¢…ëª©(ì¶”ê²©ë§¤ìˆ˜)ì€ ê±°ë¥´ëŠ” ì•ˆì „ì¥ì¹˜
            is_safe = 100.0 <= row['Disparity'] <= 106.0

            # 7. [ìˆ˜ê¸‰] OBV ìš°ìƒí–¥ ìœ ì§€
            # ì˜ë¯¸: ì£¼ê°€ëŠ” í”ë“¤ì–´ë„ ëˆ(ë§¤ì§‘ì„¸)ì€ ë¹ ì ¸ë‚˜ê°€ì§€ ì•ŠëŠ” ìƒíƒœ
            is_obv = row['OBV_Slope'] > 0

            # ğŸ† [ìµœì¢… íŒì •] 7ê°€ì§€ ì¤‘ 5ê°€ì§€ ì´ìƒ ë§Œì¡± ì‹œ 'ì •ì˜ˆ', 7ê°€ì§€ ëª¨ë‘ ë§Œì¡± ì‹œ 'LEGEND'
            conditions = [is_yeok, is_mae, is_gong, is_pa, is_volume, is_safe, is_obv]
            match_count = sum(conditions)
            
            # ğŸ’¡ ë§¤ì§‘ 5ê°€ì§€ ì¡°ê±´ ì²´í¬
            acc_1_obv_rising = (row['OBV'] > prev_5['OBV']) and (row['OBV'] > prev_10['OBV'])
            acc_2_box_range = row['Box_Range'] <= 1.15
            acc_3_macd_golden = row['MACD'] > row['MACD_Signal']
            acc_4_rsi_healthy = 40 <= row['RSI'] <= 70
            acc_5_sto_golden = row['Sto_K'] > row['Sto_D']

            # 3. ì ìˆ˜ ì‚°ì¶œ ë° íƒœê·¸ ë¶€ì—¬
            s_score = 100
            tags = []
            
            # ê¸°ì¡´ ì‹œê·¸ë„ë“¤
            if is_diamond:
                s_score += 150
                tags.append("ğŸ’ë‹¤ì´ì•„ëª¬ë“œ")
                if t_pct < 10:
                    s_score += 50
                    tags.append("ğŸ”¥í­ë°œì§ì „")
            elif is_cloud_brk:
                s_score += 40
                tags.append("â˜ï¸êµ¬ë¦„ëŒíŒŒ")

            if is_super_squeeze: 
                s_score += 40
                tags.append("ğŸ”‹ì´ˆê°•ë ¥ì‘ì¶•")
                
            if is_vol_power: 
                s_score += 30
                tags.append("âš¡ê±°ë˜í­ë°œ")
            
            # ğŸ’¡ ì—­ë§¤ê³µíŒŒ ì™„ì „ì²´ ì²´í¬
            yeok_mae_count = sum([yeok_1_ma_aligned, yeok_2_ma_converged, yeok_3_bb40_squeeze,
                                 yeok_4_red_candle, yeok_5_pullback, yeok_6_volume_surge, yeok_7_ma5_support])
            
            if yeok_mae_count == 7:
                s_score += 100
                tags.append("ğŸ¯ì—­ë§¤ê³µíŒŒì™„ì „ì²´")
            elif yeok_mae_count >= 5:
                s_score += 50
                tags.append("ğŸ¯ì—­ë§¤ê³µíŒŒê°•")
            elif yeok_mae_count >= 3:
                s_score += 20
                tags.append("ğŸ¯ì—­ë§¤ê³µíŒŒì•½")
            
            # ì„¸ë¶€ íƒœê·¸
            if yeok_1_ma_aligned and yeok_2_ma_converged:
                tags.append("ğŸ“ì´í‰ìˆ˜ë ´")
            if yeok_3_bb40_squeeze:
                tags.append("ğŸ”‹ë°´ë“œ(40)")
            
            # ğŸ’¡ ë§¤ì§‘ ì‹œê·¸ë„ ì²´í¬
            acc_count = sum([acc_1_obv_rising, acc_2_box_range, acc_3_macd_golden,
                           acc_4_rsi_healthy, acc_5_sto_golden])
            
            if acc_count >= 4:
                s_score += 60
                tags.append("ğŸ‹ì„¸ë ¥ë§¤ì§‘")
            elif acc_count >= 3:
                s_score += 30
                tags.append("ğŸ‹ë§¤ì§‘ì§•í›„")
                
            if acc_1_obv_rising:
                tags.append("ğŸ“ŠOBVìƒìŠ¹")

            # ê¸°ì¡´ ê°ì  ë¡œì§
            if t_pct > 40:
                s_score -= 25
                tags.append("âš ï¸ìœ—ê¼¬ë¦¬")

            # ê¸°ìƒë„ ê°ì 
            storm_count = sum([1 for m in ['ixic', 'sp500'] if row[f'{m}_close'] <= row[f'{m}_ma5']])
            s_score -= (storm_count * 20)
            s_score -= max(0, int((row['Disparity']-108)*5)) 
            
            if not tags: continue

            # 4. ğŸ’¡ ìˆ˜ìµë¥  ê²€ì¦ ë°ì´í„° ìƒì„± (ìµœê³ /ìµœì € ì¶”ê°€)
            h_df = df.iloc[raw_idx+1:]
            
            if not h_df.empty:
                max_r = ((h_df['High'].max() - close_p) / close_p) * 100
                min_r = ((h_df['Low'].min() - close_p) / close_p) * 100
                
                # ğŸ’¡ ì˜¤ëŠ˜ì´ë©´ í˜„ì¬ê°€ = ì˜¤ëŠ˜ ì¢…ê°€, ì•„ë‹ˆë©´ í•´ë‹¹ ì‹œì ì˜ ë§ˆì§€ë§‰ ì¢…ê°€
                is_today = (len(h_df) == 0)  # ë³´ìœ ì¼ 0ì´ë©´ ì˜¤ëŠ˜
                current_price = today_price if not is_today else close_p
            else:
                max_r = 0
                min_r = 0
                current_price = close_p

            hits.append({
                'ë‚ ì§œ': curr_idx.strftime('%Y-%m-%d'),
                'ğŸ‘‘ë“±ê¸‰': grade,              # ğŸ‘ˆ ì„œì‚¬ ì—”ì§„ ê²°ê³¼ë¬¼ 1
                'ğŸ“œì„œì‚¬íˆìŠ¤í† ë¦¬': narrative,    # ğŸ‘ˆ ì„œì‚¬ ì—”ì§„ ê²°ê³¼ë¬¼ 2
                'í™•ì‹ ì ìˆ˜': conviction,        # ğŸ‘ˆ ì„œì‚¬ ì—”ì§„ ê²°ê³¼ë¬¼ 3
                'ğŸ¯ëª©í‘œíƒ€ì ': int(target),      # ğŸ‘ˆ ì„œì‚¬ ê¸°ë°˜ íƒ€ì 
                'ğŸš¨ì†ì ˆê°€': int(stop),         # ğŸ‘ˆ ì„œì‚¬ ê¸°ë°˜ ì†ì ˆê°€
                'ê¸°ìƒ': "â˜€ï¸" * (2-storm_count) + "ğŸŒªï¸" * storm_count,
                'ì•ˆì „ì ìˆ˜': int(max(0, s_score + whale_score)),
                'ì¢…ëª©': name,
                'ë§¤ì…ê°€': int(close_p),
                'í˜„ì¬ê°€': int(current_price),
                'ê¼¬ë¦¬%': t_pct,
                'ì´ê²©': int(row['Disparity']),
                'BB40': f"{row['BB40_Width']:.1f}",
                'MAìˆ˜ë ´': f"{row['MA_Convergence']:.1f}",
                'ì—­ë§¤': f"{yeok_mae_count}/7",
                'ë§¤ì§‘': f"{acc_count}/5",
                'ìµœê³ ìˆ˜ìµë¥ %': f"{max_r:+.1f}%",
                'ìµœì €ìˆ˜ìµë¥ %': f"{min_r:+.1f}%",
                'ìµœê³ ìˆ˜ìµë¥ _raw': max_r,
                'ìµœì €ìˆ˜ìµë¥ _raw': min_r,
                'êµ¬ë¶„': " ".join(tags),
                'ë³´ìœ ì¼': len(h_df)
            })
        return hits
    except: 
        return []

# ---------------------------------------------------------
# ğŸ’¾ [ì—‘ì…€ ì €ì¥] ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª© ì €ì¥
# ---------------------------------------------------------
def save_today_recommendations(df_today, recommendation_info):
    """ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª©ì„ ì—‘ì…€ë¡œ ì €ì¥"""
    try:
        filename = f"ì¶”ì²œì¢…ëª©_{TODAY_STR}.xlsx"
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # ì‹œíŠ¸1: ì˜¤ëŠ˜ì˜ ì¶”ì²œ ì¢…ëª©
            df_today.to_excel(writer, sheet_name='ì˜¤ëŠ˜ì˜_ì¶”ì²œ', index=False)
            
            # ì‹œíŠ¸2: ì¶”ì²œ ì •ë³´
            if recommendation_info:
                rec_df = pd.DataFrame([recommendation_info])
                rec_df.to_excel(writer, sheet_name='ì¶”ì²œ_íŒ¨í„´_ì •ë³´', index=False)
        
        print(f"\nğŸ’¾ ì—‘ì…€ ì €ì¥ ì™„ë£Œ: {filename}")
        return filename
    except Exception as e:
        print(f"\nâŒ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

# =================================================
# ğŸš€ [ì‹¤í–‰] ë©”ì¸ ì»¨íŠ¸ë¡¤ëŸ¬ (ìˆ˜ì • ë²„ì „)
# =================================================
if __name__ == "__main__":
    print(f"ğŸ“¡ [Ver 36.7 êµ¬ê¸€ì‹œíŠ¸ ê°•í™”] {TODAY_STR} ì „ìˆ  ì‚¬ë ¹ë¶€ í†µí•© ê°€ë™...")
    commander_cap_map = get_commander_market_cap()
    # ê¸€ë¡œë²Œ ë° ëŒ€ì¥ì£¼ ìƒíƒœ ë¯¸ë¦¬ í™•ë³´ (í•œ ë²ˆë§Œ ì‹¤í–‰)
    g_status, l_sync = get_global_and_leader_status()
  
    # 1. ë§¤í¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
    m_ndx = get_safe_macro('^IXIC', 'ë‚˜ìŠ¤ë‹¥')
    m_sp5 = get_safe_macro('^GSPC', 'S&P500')
    m_vix = get_safe_macro('^VIX', 'VIXê³µí¬')
    m_fx  = get_safe_macro('USD/KRW', 'ë‹¬ëŸ¬í™˜ìœ¨')
    
    kospi_supply = get_index_investor_data('KOSPI')
    macro_status = {'nasdaq': m_ndx, 'sp500': m_sp5, 'vix': m_vix, 'fx': m_fx, 'kospi': kospi_supply}

    print("\n" + "ğŸŒ " * 5 + "[ ê¸€ë¡œë²Œ ì‚¬ë ¹ë¶€ í†µí•© ê´€ì œ ì„¼í„° ]" + " ğŸŒ" * 5)
    print(f"ğŸ‡ºğŸ‡¸ {m_ndx['text']} | {m_sp5['text']} | âš ï¸ {m_vix['text']}")
    print(f"ğŸ’µ {m_fx['text']} | ğŸ‡°ğŸ‡· KOSPI ìˆ˜ê¸‰: {kospi_supply}")
    print("=" * 115)

    # 2. ì „ ì¢…ëª© ë¦¬ìŠ¤íŒ… ë° ê¸°ìƒë„ ì¤€ë¹„
    df_krx = fdr.StockListing('KRX')
    target_stocks = df_krx.sort_values(by='Amount', ascending=False).head(TOP_N)
    weather_data = prepare_historical_weather()

    # ğŸ’¡ [í•µì‹¬] ì„¹í„° ë§ˆìŠ¤í„° ë§µ ìƒì„± (ì¢…ëª©ì½”ë“œ: ì—…ì¢…ëª…)
    # ì´ í•œ ì¤„ë¡œ 2,500ê°œ ì¢…ëª©ì˜ ì„¹í„° ì§€ë„ê°€ ì™„ì„±ë©ë‹ˆë‹¤.
    sector_master_map = df_krx.set_index('Symbol')['Sector'].to_dict()
    
    # 2. ê¸€ë¡œë²Œ/ëŒ€ì¥ì£¼ ìƒíƒœ ìŠ¤ìº”
    g_status, l_sync = get_global_and_leader_status()
  
    # 3. ì „ìˆ  ìŠ¤ìº” (ë©€í‹°ìŠ¤ë ˆë”©)
    all_hits = []
    print(f"ğŸ” ì´ {len(target_stocks)}ê°œ ì¢…ëª© ğŸ’ë‹¤ì´ì•„ëª¬ë“œ & ğŸ¯ì—­ë§¤ê³µíŒŒ ë ˆì´ë” ê°€ë™...")
    with ThreadPoolExecutor(max_workers=15) as executor:
        results = list(executor.map(
            lambda p: analyze_final(p[0], p[1], weather_data, g_status, l_sync, sector_master_map), 
            zip(target_stocks['Code'], target_stocks['Name'])
        ))
        for r in results:
            if r:
                # ğŸ’¡ [ì‹ ê·œ] í¬ì°©ëœ ì¢…ëª©ì— ì¦‰ì‹œ ì²´ê¸‰(Tier) ë° ì‹œì´ ë°ì´í„° ì£¼ì…
                for hit in r:
                    # hit['ì¢…ëª©ì½”ë“œ']ê°€ ìˆë‹¤ê³  ê°€ì •, ì—†ìœ¼ë©´ tickerë¥¼ ì°¾ì•„ì•¼ í•¨
                    name = hit['ì¢…ëª©']
                    ticker_code = hit.get('ì½”ë“œ')
                    tier, mkt_cap = assign_tier(ticker_code, name, commander_cap_map)
                    hit['ì²´ê¸‰'] = tier
                    hit['ì‹œê°€ì´ì•¡'] = mkt_cap
                    all_hits.append(hit)

    if all_hits:
         # 1. ì›ì¬ë£Œ(all_hits)ë¥¼ ì—°êµ¬ì†Œ(DNA_Analyzer)ë¡œ ì†¡ë¶€
        print("ğŸ§¬ [DNA Trace-Back] ì„±ê³µ ìœ ì „ì ì—­ì¶”ì  ê°€ë™...")
        dna_results = analyze_dna_sequences(all_hits)
    
        # 2. ê°€ì¥ ìŠ¹ë¥  ë†’ì€ íŒ¨í„´ ë­í‚¹ ì¶”ì¶œ
        top_patterns = find_winning_pattern(dna_results)

        df_total = pd.DataFrame(all_hits)
        
        # í†µê³„ ê³„ì‚° (ìƒìœ„ 5ê°œ ì¶”ì²œ ì •ë³´ í¬í•¨)
        stats_df, top_recommendations = calculate_strategy_stats(all_hits)
        
        # 4. ê²°ê³¼ ë¶„ë¥˜
        today = df_total[df_total['ë³´ìœ ì¼'] == 0].sort_values(by='ì•ˆì „ì ìˆ˜', ascending=False)
        
        # ì¶”ì²œ íŒ¨í„´ DataFrame ìƒì„±
        if top_recommendations:
            recommendation_df = pd.DataFrame(top_recommendations)
            recommendation_df['ë‚ ì§œ'] = TODAY_STR
            recommendation_df = recommendation_df[['ë‚ ì§œ', 'ìˆœìœ„', 'íŒ¨í„´', 'íƒ€ìœ¨', 'í‰ê· ìˆ˜ìµ', 'ê¸°ëŒ€ê°’', 'ê±´ìˆ˜', 'ì‹ ë¢°ë„']]
        else:
            recommendation_df = pd.DataFrame()
        
        # ğŸ’¡ ì¶”ì²œ íŒ¨í„´ ì¶œë ¥ (ì—¬ëŸ¬ ê°œ)
        if top_recommendations:
            print("\n" + "ğŸ† " * 10 + "[ AI ì¶”ì²œ TOP 5 íŒ¨í„´ ]" + " ğŸ†" * 10)
            for i, rec in enumerate(top_recommendations, 1):
                medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}ìœ„"
                print(f"\n{medal} [{rec['íŒ¨í„´']}]")
                print(f"   ğŸ“Š íƒ€ìœ¨ {rec['íƒ€ìœ¨']}% | í‰ê· ìˆ˜ìµ {rec['í‰ê· ìˆ˜ìµ']}% | ê¸°ëŒ€ê°’ {rec['ê¸°ëŒ€ê°’']} | ê±´ìˆ˜ {rec['ê±´ìˆ˜']}ê±´")
                print(f"   {rec['ì‹ ë¢°ë„']}")
            print("=" * 100)
            
        if not top_patterns.empty:
    # ğŸ’¡ 1. 'top_patterns' ë°ì´í„°í”„ë ˆì„ì—ì„œ 1ìˆœìœ„ íŒ¨í„´ ë¬¸ìì—´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    # DNA_ì‹œí€€ìŠ¤ ì»¬ëŸ¼ì˜ ì²« ë²ˆì§¸ í–‰(iloc[0])ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            best_pattern_str = top_patterns.iloc[0]['DNA_ì‹œí€€ìŠ¤']
    
    # ğŸ’¡ 2. íŒ¨í„´ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ(ì˜ˆ: 'ë§¤ì§‘ë´‰')ë§Œ ë–¼ì–´ë‚´ì–´ ì˜¤ëŠ˜ ì¢…ëª©ì„ í•„í„°ë§í•©ë‹ˆë‹¤.
    # ì‚¬ë ¹ê´€ë‹˜ì´ ì‘ì„±í•˜ì‹  split logicì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            target_tag = best_pattern_str.split(' â” ')[0] # 'â”' ê¸°í˜¸ ê¸°ì¤€ ì²« íƒœê·¸ ì¶”ì¶œ
    
            print(f"ğŸ¯ [DNA í•„í„°] ì˜¤ëŠ˜ì˜ 1ìˆœìœ„ íƒ€ê²Ÿ íŒ¨í„´: {target_tag}")
    
    # ğŸ’¡ 3. ì˜¤ëŠ˜ ë°ì´í„°(today)ì—ì„œ í•´ë‹¹ íƒœê·¸ê°€ í¬í•¨ëœ ì¢…ëª©ë§Œ ì¶”ì¶œ
            recommended_today = today[today['êµ¬ë¶„'].str.contains(target_tag, na=False)]
        else:
            print("âš ï¸ [DNA í•„í„°] ìœ íš¨í•œ ì„±ê³µ íŒ¨í„´ì´ ì—†ì–´ ì „ì²´ ì¢…ëª©ì„ ìœ ì§€í•©ë‹ˆë‹¤.")
            recommended_today = today.copy()

            # 1ìœ„ íŒ¨í„´ì´ í¬í•¨ëœ ì˜¤ëŠ˜ì˜ ì¢…ëª© í•„í„°ë§
            top_pattern = top_recommendations[0]['íŒ¨í„´']
            recommended_today = today[today['êµ¬ë¶„'].str.contains(top_pattern.split(' + ')[0], na=False)]
            if not recommended_today.empty:
                print(f"\nâœ¨ ì˜¤ëŠ˜ì˜ '{top_pattern}' íŒ¨í„´ ì¢…ëª©")
                print(recommended_today[['ì¢…ëª©', 'ì•ˆì „ì ìˆ˜', 'ë§¤ì…ê°€', 'ì—­ë§¤', 'ë§¤ì§‘', 'êµ¬ë¶„']].head(10))
        
        # ğŸ’¡ í†µí•©: ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª© (ì—­ë§¤ê³µíŒŒ í¬í•¨, ì•ˆì „ì ìˆ˜ ìˆœ)
        print("\n" + "ğŸ¯ " * 10 + "[ ì˜¤ëŠ˜ì˜ ì¶”ì²œì¢…ëª© TOP 50 ]" + " ğŸ¯" * 10)
        print("(ì—­ë§¤ê³µíŒŒ, ë‹¤ì´ì•„ëª¬ë“œ, ì„¸ë ¥ë§¤ì§‘ ë“± ëª¨ë“  íŒ¨í„´ í¬í•¨ / ì•ˆì „ì ìˆ˜ ìˆœ)")
        print("=" * 120)
        
        if not today.empty:
            display_cols = ['ì²´ê¸‰', 'ì¢…ëª©', 'ì•ˆì „ì ìˆ˜', 'ë§¤ì…ê°€', 'í˜„ì¬ê°€', 'ê¼¬ë¦¬%', 'ì—­ë§¤', 'ë§¤ì§‘', 'BB40', 'MAìˆ˜ë ´', 'êµ¬ë¶„']
            print(today[display_cols].head(50))
            
            # ğŸ’¡ íŒ¨í„´ë³„ ì§‘ê³„ (ì°¸ê³ ìš©)
            diamond_count = len(today[today['êµ¬ë¶„'].str.contains('ë‹¤ì´ì•„ëª¬ë“œ', na=False)])
            yeok_complete = len(today[today['êµ¬ë¶„'].str.contains('ì—­ë§¤ê³µíŒŒì™„ì „ì²´', na=False)])
            yeok_strong = len(today[today['êµ¬ë¶„'].str.contains('ì—­ë§¤ê³µíŒŒê°•', na=False)])
            accumulation = len(today[today['êµ¬ë¶„'].str.contains('ì„¸ë ¥ë§¤ì§‘', na=False)])
            
            print("\nğŸ“Š [ ì˜¤ëŠ˜ì˜ íŒ¨í„´ ë¶„í¬ ]")
            print(f"   ğŸ’ ë‹¤ì´ì•„ëª¬ë“œ: {diamond_count}ê°œ")
            print(f"   ğŸ¯ ì—­ë§¤ê³µíŒŒ ì™„ì „ì²´: {yeok_complete}ê°œ")
            print(f"   ğŸ¯ ì—­ë§¤ê³µíŒŒ ê°•: {yeok_strong}ê°œ")
            print(f"   ğŸ‹ ì„¸ë ¥ë§¤ì§‘: {accumulation}ê°œ")
            print(f"   ğŸ“ˆ ì „ì²´ ì¶”ì²œì¢…ëª©: {len(today)}ê°œ")
        else:
            print("ì˜¤ëŠ˜ì€ ì¶”ì²œí•  ë§Œí•œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

        print("\n" + "ğŸ“Š [ì „ëµë³„ í†µê³„ (ê³¼ê±° 30ì¼)] " + "="*70)
        if not stats_df.empty:
            print(stats_df.head(20))

        # 5. êµ¬ê¸€ ì‹œíŠ¸ ì „ì†¡
        try:
            update_commander_dashboard(
                df_total,  # ë©”ì¸ ì‹œíŠ¸: ì „ì²´ 30ì¼ ë°ì´í„°
                macro_status, 
                "ì‚¬ë ¹ë¶€_í†µí•©_ìƒí™©íŒ", 
                stats_df,
                today,  # ì˜¤ëŠ˜ì˜_ì¶”ì²œì¢…ëª© íƒ­: ì˜¤ëŠ˜ë§Œ (ëª¨ë“  íŒ¨í„´ í†µí•©)
                ai_recommendation=dna_results  # AI_ì¶”ì²œíŒ¨í„´ íƒ­: TOP 5
            )
            print("\nâœ… êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì„±ê³µ!")
            print("   ğŸ“‹ ë©”ì¸ ì‹œíŠ¸: ì „ì²´ 30ì¼ ê²€ì¦ ë°ì´í„°")
            print("   ğŸ¯ ì˜¤ëŠ˜ì˜_ì¶”ì²œì¢…ëª© íƒ­: ì˜¤ëŠ˜ ì‹ í˜¸ë§Œ (TOP 50, ëª¨ë“  íŒ¨í„´ í†µí•©)")
            print("   ğŸ† AI_ì¶”ì²œíŒ¨í„´ íƒ­: TOP 5 íŒ¨í„´ ë¶„ì„")
        except Exception as e:
            print(f"\nâŒ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    else:
        print("\nâš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
